{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lzk7iX_CodX6",
    "tags": []
   },
   "source": [
    "# <img align=\"left\" src=\"./images/film_strip_vertical.png\"     style=\" width:40px;  \" > Practice lab: Deep Learning for Content-Based Filtering\n",
    "\n",
    "In this exercise, you will implement content-based filtering using a neural network to build a recommender system for movies. \n",
    "\n",
    "\n",
    "# Outline\n",
    "- [ 1 - Packages ](#1)\n",
    "- [ 2 - Movie ratings dataset ](#2)\n",
    "- [ 3 - Content-based filtering with a neural network](#3)\n",
    "  - [ 3.1 Training Data](#3.1)\n",
    "  - [ 3.2 Preparing the training data](#3.2)\n",
    "- [ 4 - Neural Network for content-based filtering](#4)\n",
    "  - [ Exercise 1](#ex01)\n",
    "- [ 5 - Predictions](#5)\n",
    "  - [ 5.1 - Predictions for a new user](#5.1)\n",
    "  - [ 5.2 - Predictions for an existing user.](#5.2)\n",
    "  - [ 5.3 - Finding Similar Items](#5.3)\n",
    "    - [ Exercise 2](#ex02)\n",
    "- [ 6 - Congratulations! ](#6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_**NOTE:** To prevent errors from the autograder, you are not allowed to edit or delete non-graded cells in this lab. Please also refrain from adding any new cells. \n",
    "**Once you have passed this assignment** and want to experiment with any of the non-graded code, you may follow the instructions at the bottom of this notebook._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"1\"></a>\n",
    "## 1 - Packages <img align=\"left\" src=\"./images/movie_camera.png\"     style=\" width:40px;  \">\n",
    "We will use familiar packages, NumPy, TensorFlow and helpful routines from [scikit-learn](https://scikit-learn.org/stable/). We will also use [tabulate](https://pypi.org/project/tabulate/) to neatly print tables and [Pandas](https://pandas.pydata.org/) to organize tabular data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "Xu-w_RmNwCV5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tabulate\n",
    "from recsysNN_utils import *\n",
    "pd.set_option(\"display.precision\", 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"2\"></a>\n",
    "## 2 - Movie ratings dataset <img align=\"left\" src=\"./images/film_rating.png\" style=\" width:40px;\" >\n",
    "The data set is derived from the [MovieLens ml-latest-small](https://grouplens.org/datasets/movielens/latest/) dataset. \n",
    "\n",
    "[F. Maxwell Harper and Joseph A. Konstan. 2015. The MovieLens Datasets: History and Context. ACM Transactions on Interactive Intelligent Systems (TiiS) 5, 4: 19:1â€“19:19. <https://doi.org/10.1145/2827872>]\n",
    "\n",
    "The original dataset has roughly 9000 movies rated by 600 users with ratings on a scale of 0.5 to 5 in 0.5 step increments. The dataset has been reduced in size to focus on movies from the years since 2000 and popular genres. The reduced dataset has $n_u = 397$ users, $n_m= 847$ movies and 25521 ratings. For each movie, the dataset provides a movie title, release date, and one or more genres. For example \"Toy Story 3\" was released in 2010 and has several genres: \"Adventure|Animation|Children|Comedy|Fantasy\". This dataset contains little information about users other than their ratings. This dataset is used to create training vectors for the neural networks described below. \n",
    "Let's learn a bit more about this data set. The table below shows the top 10 movies ranked by the number of ratings. These movies also happen to have high average ratings. How many of these movies have you watched? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie id</th>\n",
       "      <th>num ratings</th>\n",
       "      <th>ave rating</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4993</td>\n",
       "      <td>198</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Lord of the Rings: The Fellowship of the Ring,...</td>\n",
       "      <td>Adventure|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5952</td>\n",
       "      <td>188</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Lord of the Rings: The Two Towers, The</td>\n",
       "      <td>Adventure|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7153</td>\n",
       "      <td>185</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Lord of the Rings: The Return of the King, The</td>\n",
       "      <td>Action|Adventure|Drama|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4306</td>\n",
       "      <td>170</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Shrek</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy|Ro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>58559</td>\n",
       "      <td>149</td>\n",
       "      <td>4.2</td>\n",
       "      <td>Dark Knight, The</td>\n",
       "      <td>Action|Crime|Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6539</td>\n",
       "      <td>149</td>\n",
       "      <td>3.8</td>\n",
       "      <td>Pirates of the Caribbean: The Curse of the Bla...</td>\n",
       "      <td>Action|Adventure|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>79132</td>\n",
       "      <td>143</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Inception</td>\n",
       "      <td>Action|Crime|Drama|Mystery|Sci-Fi|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6377</td>\n",
       "      <td>141</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Finding Nemo</td>\n",
       "      <td>Adventure|Animation|Children|Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4886</td>\n",
       "      <td>132</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Monsters, Inc.</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7361</td>\n",
       "      <td>131</td>\n",
       "      <td>4.2</td>\n",
       "      <td>Eternal Sunshine of the Spotless Mind</td>\n",
       "      <td>Drama|Romance|Sci-Fi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movie id  num ratings  ave rating  \\\n",
       "0      4993          198         4.1   \n",
       "1      5952          188         4.0   \n",
       "2      7153          185         4.1   \n",
       "3      4306          170         3.9   \n",
       "4     58559          149         4.2   \n",
       "5      6539          149         3.8   \n",
       "6     79132          143         4.1   \n",
       "7      6377          141         4.0   \n",
       "8      4886          132         3.9   \n",
       "9      7361          131         4.2   \n",
       "\n",
       "                                               title  \\\n",
       "0  Lord of the Rings: The Fellowship of the Ring,...   \n",
       "1             Lord of the Rings: The Two Towers, The   \n",
       "2     Lord of the Rings: The Return of the King, The   \n",
       "3                                              Shrek   \n",
       "4                                   Dark Knight, The   \n",
       "5  Pirates of the Caribbean: The Curse of the Bla...   \n",
       "6                                          Inception   \n",
       "7                                       Finding Nemo   \n",
       "8                                     Monsters, Inc.   \n",
       "9              Eternal Sunshine of the Spotless Mind   \n",
       "\n",
       "                                              genres  \n",
       "0                                  Adventure|Fantasy  \n",
       "1                                  Adventure|Fantasy  \n",
       "2                     Action|Adventure|Drama|Fantasy  \n",
       "3  Adventure|Animation|Children|Comedy|Fantasy|Ro...  \n",
       "4                                 Action|Crime|Drama  \n",
       "5                    Action|Adventure|Comedy|Fantasy  \n",
       "6         Action|Crime|Drama|Mystery|Sci-Fi|Thriller  \n",
       "7                Adventure|Animation|Children|Comedy  \n",
       "8        Adventure|Animation|Children|Comedy|Fantasy  \n",
       "9                               Drama|Romance|Sci-Fi  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top10_df = pd.read_csv(\"./data/content_top10_df.csv\")\n",
    "bygenre_df = pd.read_csv(\"./data/content_bygenre_df.csv\")\n",
    "top10_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next table shows information sorted by genre. The number of ratings per genre vary substantially. Note that a movie may have multiple genre's so the sum of the ratings below is larger than the number of original ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genre</th>\n",
       "      <th>num movies</th>\n",
       "      <th>ave rating/genre</th>\n",
       "      <th>ratings per genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Action</td>\n",
       "      <td>321</td>\n",
       "      <td>3.4</td>\n",
       "      <td>10377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adventure</td>\n",
       "      <td>234</td>\n",
       "      <td>3.4</td>\n",
       "      <td>8785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Animation</td>\n",
       "      <td>76</td>\n",
       "      <td>3.6</td>\n",
       "      <td>2588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Children</td>\n",
       "      <td>69</td>\n",
       "      <td>3.4</td>\n",
       "      <td>2472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Comedy</td>\n",
       "      <td>326</td>\n",
       "      <td>3.4</td>\n",
       "      <td>8911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Crime</td>\n",
       "      <td>139</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Documentary</td>\n",
       "      <td>13</td>\n",
       "      <td>3.8</td>\n",
       "      <td>280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Drama</td>\n",
       "      <td>342</td>\n",
       "      <td>3.6</td>\n",
       "      <td>10201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Fantasy</td>\n",
       "      <td>124</td>\n",
       "      <td>3.4</td>\n",
       "      <td>4468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Horror</td>\n",
       "      <td>56</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Mystery</td>\n",
       "      <td>68</td>\n",
       "      <td>3.6</td>\n",
       "      <td>2497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Romance</td>\n",
       "      <td>151</td>\n",
       "      <td>3.4</td>\n",
       "      <td>4468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Sci-Fi</td>\n",
       "      <td>174</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Thriller</td>\n",
       "      <td>245</td>\n",
       "      <td>3.4</td>\n",
       "      <td>7659</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          genre  num movies  ave rating/genre  ratings per genre\n",
       "0        Action         321               3.4              10377\n",
       "1     Adventure         234               3.4               8785\n",
       "2     Animation          76               3.6               2588\n",
       "3      Children          69               3.4               2472\n",
       "4        Comedy         326               3.4               8911\n",
       "5         Crime         139               3.5               4671\n",
       "6   Documentary          13               3.8                280\n",
       "7         Drama         342               3.6              10201\n",
       "8       Fantasy         124               3.4               4468\n",
       "9        Horror          56               3.2               1345\n",
       "10      Mystery          68               3.6               2497\n",
       "11      Romance         151               3.4               4468\n",
       "12       Sci-Fi         174               3.4               5894\n",
       "13     Thriller         245               3.4               7659"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bygenre_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"3\"></a>\n",
    "## 3 - Content-based filtering with a neural network\n",
    "\n",
    "In the collaborative filtering lab, you generated two vectors, a user vector and an item/movie vector whose dot product would predict a rating. The vectors were derived solely from the ratings.   \n",
    "\n",
    "Content-based filtering also generates a user and movie feature vector but recognizes there may be other information available about the user and/or movie that may improve the prediction. The additional information is provided to a neural network which then generates the user and movie vector as shown below.\n",
    "<figure>\n",
    "    <center> <img src=\"./images/RecSysNN.png\"   style=\"width:500px;height:280px;\" ></center>\n",
    "</figure>\n",
    "\n",
    "<a name=\"3.1\"></a>\n",
    "### 3.1 Training Data\n",
    "The movie content provided to the network is a combination of the original data and some 'engineered features'. Recall the feature engineering discussion and lab from Course 1, Week 2, lab 4. The original features are the year the movie was released and the movie's genre's presented as a one-hot vector. There are 14 genres. The engineered feature is an average rating derived from the user ratings. \n",
    "\n",
    "The user content is composed of engineered features. A per genre average rating is computed per user. Additionally, a user id, rating count and rating average are available but not included in the training or prediction content. They are carried with the data set because they are useful in interpreting data.\n",
    "\n",
    "The training set consists of all the ratings made by the users in the data set. Some ratings are repeated to boost the number of training examples of underrepresented genre's. The training set is split into two arrays with the same number of entries, a user array and a movie/item array.  \n",
    "\n",
    "Below, let's load and display some of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.  , 22.  ,  4.  ,  3.95,  4.25,  0.  ,  0.  ,  4.  ,  4.12,\n",
       "         4.  ,  4.04,  0.  ,  3.  ,  4.  ,  0.  ,  3.88,  3.89],\n",
       "       [ 2.  , 22.  ,  4.  ,  3.95,  4.25,  0.  ,  0.  ,  4.  ,  4.12,\n",
       "         4.  ,  4.04,  0.  ,  3.  ,  4.  ,  0.  ,  3.88,  3.89],\n",
       "       [ 2.  , 22.  ,  4.  ,  3.95,  4.25,  0.  ,  0.  ,  4.  ,  4.12,\n",
       "         4.  ,  4.04,  0.  ,  3.  ,  4.  ,  0.  ,  3.88,  3.89]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_train, user_train, y_train, item_features, user_features, item_vecs, movie_dict, user_to_genre = load_data()\n",
    "user_train.shape #(50884, 17)\n",
    "user_train[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50884, 17)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "M5gfMLYgxCD1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training vectors: 50884\n"
     ]
    }
   ],
   "source": [
    "# Load Data, set configuration variables\n",
    "item_train, user_train, y_train, item_features, user_features, item_vecs, movie_dict, user_to_genre = load_data()\n",
    "\n",
    "num_user_features = user_train.shape[1] - 3  # remove userid, rating count and ave rating during training\n",
    "num_item_features = item_train.shape[1] - 1  # remove movie id at train time\n",
    "uvs = 3  # user genre vector start\n",
    "ivs = 3  # item genre vector start\n",
    "u_s = 3  # start of columns to use in training, user\n",
    "i_s = 1  # start of columns to use in training, items\n",
    "print(f\"Number of training vectors: {len(item_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_user_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_item_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.05400000e+03, 2.00100000e+03, 2.84375000e+00, ...,\n",
       "        1.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [4.06900000e+03, 2.00100000e+03, 2.90909091e+00, ...,\n",
       "        1.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [4.14800000e+03, 2.00100000e+03, 2.93589744e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.00000000e+00],\n",
       "       ...,\n",
       "       [1.77765000e+05, 2.01700000e+03, 3.53846154e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [1.79819000e+05, 2.01700000e+03, 3.12500000e+00, ...,\n",
       "        0.00000000e+00, 1.00000000e+00, 0.00000000e+00],\n",
       "       [1.87593000e+05, 2.01800000e+03, 3.87500000e+00, ...,\n",
       "        0.00000000e+00, 1.00000000e+00, 0.00000000e+00]], shape=(847, 17))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_vecs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the first few entries in the user training array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th style=\"text-align: center;\"> [user id] </th><th style=\"text-align: center;\"> [rating count] </th><th style=\"text-align: center;\"> [rating ave] </th><th style=\"text-align: center;\"> Act ion </th><th style=\"text-align: center;\"> Adve nture </th><th style=\"text-align: center;\"> Anim ation </th><th style=\"text-align: center;\"> Chil dren </th><th style=\"text-align: center;\"> Com edy </th><th style=\"text-align: center;\"> Crime </th><th style=\"text-align: center;\"> Docum entary </th><th style=\"text-align: center;\"> Drama </th><th style=\"text-align: center;\"> Fan tasy </th><th style=\"text-align: center;\"> Hor ror </th><th style=\"text-align: center;\"> Mys tery </th><th style=\"text-align: center;\"> Rom ance </th><th style=\"text-align: center;\"> Sci -Fi </th><th style=\"text-align: center;\"> Thri ller </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: center;\">     2     </td><td style=\"text-align: center;\">       22       </td><td style=\"text-align: center;\">     4.0      </td><td style=\"text-align: center;\">   4.0   </td><td style=\"text-align: center;\">    4.2     </td><td style=\"text-align: center;\">    0.0     </td><td style=\"text-align: center;\">    0.0    </td><td style=\"text-align: center;\">   4.0   </td><td style=\"text-align: center;\">  4.1  </td><td style=\"text-align: center;\">     4.0      </td><td style=\"text-align: center;\">  4.0  </td><td style=\"text-align: center;\">   0.0    </td><td style=\"text-align: center;\">   3.0   </td><td style=\"text-align: center;\">   4.0    </td><td style=\"text-align: center;\">   0.0    </td><td style=\"text-align: center;\">   3.9   </td><td style=\"text-align: center;\">    3.9    </td></tr>\n",
       "<tr><td style=\"text-align: center;\">     2     </td><td style=\"text-align: center;\">       22       </td><td style=\"text-align: center;\">     4.0      </td><td style=\"text-align: center;\">   4.0   </td><td style=\"text-align: center;\">    4.2     </td><td style=\"text-align: center;\">    0.0     </td><td style=\"text-align: center;\">    0.0    </td><td style=\"text-align: center;\">   4.0   </td><td style=\"text-align: center;\">  4.1  </td><td style=\"text-align: center;\">     4.0      </td><td style=\"text-align: center;\">  4.0  </td><td style=\"text-align: center;\">   0.0    </td><td style=\"text-align: center;\">   3.0   </td><td style=\"text-align: center;\">   4.0    </td><td style=\"text-align: center;\">   0.0    </td><td style=\"text-align: center;\">   3.9   </td><td style=\"text-align: center;\">    3.9    </td></tr>\n",
       "<tr><td style=\"text-align: center;\">     2     </td><td style=\"text-align: center;\">       22       </td><td style=\"text-align: center;\">     4.0      </td><td style=\"text-align: center;\">   4.0   </td><td style=\"text-align: center;\">    4.2     </td><td style=\"text-align: center;\">    0.0     </td><td style=\"text-align: center;\">    0.0    </td><td style=\"text-align: center;\">   4.0   </td><td style=\"text-align: center;\">  4.1  </td><td style=\"text-align: center;\">     4.0      </td><td style=\"text-align: center;\">  4.0  </td><td style=\"text-align: center;\">   0.0    </td><td style=\"text-align: center;\">   3.0   </td><td style=\"text-align: center;\">   4.0    </td><td style=\"text-align: center;\">   0.0    </td><td style=\"text-align: center;\">   3.9   </td><td style=\"text-align: center;\">    3.9    </td></tr>\n",
       "<tr><td style=\"text-align: center;\">     2     </td><td style=\"text-align: center;\">       22       </td><td style=\"text-align: center;\">     4.0      </td><td style=\"text-align: center;\">   4.0   </td><td style=\"text-align: center;\">    4.2     </td><td style=\"text-align: center;\">    0.0     </td><td style=\"text-align: center;\">    0.0    </td><td style=\"text-align: center;\">   4.0   </td><td style=\"text-align: center;\">  4.1  </td><td style=\"text-align: center;\">     4.0      </td><td style=\"text-align: center;\">  4.0  </td><td style=\"text-align: center;\">   0.0    </td><td style=\"text-align: center;\">   3.0   </td><td style=\"text-align: center;\">   4.0    </td><td style=\"text-align: center;\">   0.0    </td><td style=\"text-align: center;\">   3.9   </td><td style=\"text-align: center;\">    3.9    </td></tr>\n",
       "<tr><td style=\"text-align: center;\">     2     </td><td style=\"text-align: center;\">       22       </td><td style=\"text-align: center;\">     4.0      </td><td style=\"text-align: center;\">   4.0   </td><td style=\"text-align: center;\">    4.2     </td><td style=\"text-align: center;\">    0.0     </td><td style=\"text-align: center;\">    0.0    </td><td style=\"text-align: center;\">   4.0   </td><td style=\"text-align: center;\">  4.1  </td><td style=\"text-align: center;\">     4.0      </td><td style=\"text-align: center;\">  4.0  </td><td style=\"text-align: center;\">   0.0    </td><td style=\"text-align: center;\">   3.0   </td><td style=\"text-align: center;\">   4.0    </td><td style=\"text-align: center;\">   0.0    </td><td style=\"text-align: center;\">   3.9   </td><td style=\"text-align: center;\">    3.9    </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "'<table>\\n<thead>\\n<tr><th style=\"text-align: center;\"> [user id] </th><th style=\"text-align: center;\"> [rating count] </th><th style=\"text-align: center;\"> [rating ave] </th><th style=\"text-align: center;\"> Act ion </th><th style=\"text-align: center;\"> Adve nture </th><th style=\"text-align: center;\"> Anim ation </th><th style=\"text-align: center;\"> Chil dren </th><th style=\"text-align: center;\"> Com edy </th><th style=\"text-align: center;\"> Crime </th><th style=\"text-align: center;\"> Docum entary </th><th style=\"text-align: center;\"> Drama </th><th style=\"text-align: center;\"> Fan tasy </th><th style=\"text-align: center;\"> Hor ror </th><th style=\"text-align: center;\"> Mys tery </th><th style=\"text-align: center;\"> Rom ance </th><th style=\"text-align: center;\"> Sci -Fi </th><th style=\"text-align: center;\"> Thri ller </th></tr>\\n</thead>\\n<tbody>\\n<tr><td style=\"text-align: center;\">     2     </td><td style=\"text-align: center;\">       22       </td><td style=\"text-align: center;\">     4.0      </td><td style=\"text-align: center;\">   4.0   </td><td style=\"text-align: center;\">    4.2     </td><td style=\"text-align: center;\">    0.0     </td><td style=\"text-align: center;\">    0.0    </td><td style=\"text-align: center;\">   4.0   </td><td style=\"text-align: center;\">  4.1  </td><td style=\"text-align: center;\">     4.0      </td><td style=\"text-align: center;\">  4.0  </td><td style=\"text-align: center;\">   0.0    </td><td style=\"text-align: center;\">   3.0   </td><td style=\"text-align: center;\">   4.0    </td><td style=\"text-align: center;\">   0.0    </td><td style=\"text-align: center;\">   3.9   </td><td style=\"text-align: center;\">    3.9    </td></tr>\\n<tr><td style=\"text-align: center;\">     2     </td><td style=\"text-align: center;\">       22       </td><td style=\"text-align: center;\">     4.0      </td><td style=\"text-align: center;\">   4.0   </td><td style=\"text-align: center;\">    4.2     </td><td style=\"text-align: center;\">    0.0     </td><td style=\"text-align: center;\">    0.0    </td><td style=\"text-align: center;\">   4.0   </td><td style=\"text-align: center;\">  4.1  </td><td style=\"text-align: center;\">     4.0      </td><td style=\"text-align: center;\">  4.0  </td><td style=\"text-align: center;\">   0.0    </td><td style=\"text-align: center;\">   3.0   </td><td style=\"text-align: center;\">   4.0    </td><td style=\"text-align: center;\">   0.0    </td><td style=\"text-align: center;\">   3.9   </td><td style=\"text-align: center;\">    3.9    </td></tr>\\n<tr><td style=\"text-align: center;\">     2     </td><td style=\"text-align: center;\">       22       </td><td style=\"text-align: center;\">     4.0      </td><td style=\"text-align: center;\">   4.0   </td><td style=\"text-align: center;\">    4.2     </td><td style=\"text-align: center;\">    0.0     </td><td style=\"text-align: center;\">    0.0    </td><td style=\"text-align: center;\">   4.0   </td><td style=\"text-align: center;\">  4.1  </td><td style=\"text-align: center;\">     4.0      </td><td style=\"text-align: center;\">  4.0  </td><td style=\"text-align: center;\">   0.0    </td><td style=\"text-align: center;\">   3.0   </td><td style=\"text-align: center;\">   4.0    </td><td style=\"text-align: center;\">   0.0    </td><td style=\"text-align: center;\">   3.9   </td><td style=\"text-align: center;\">    3.9    </td></tr>\\n<tr><td style=\"text-align: center;\">     2     </td><td style=\"text-align: center;\">       22       </td><td style=\"text-align: center;\">     4.0      </td><td style=\"text-align: center;\">   4.0   </td><td style=\"text-align: center;\">    4.2     </td><td style=\"text-align: center;\">    0.0     </td><td style=\"text-align: center;\">    0.0    </td><td style=\"text-align: center;\">   4.0   </td><td style=\"text-align: center;\">  4.1  </td><td style=\"text-align: center;\">     4.0      </td><td style=\"text-align: center;\">  4.0  </td><td style=\"text-align: center;\">   0.0    </td><td style=\"text-align: center;\">   3.0   </td><td style=\"text-align: center;\">   4.0    </td><td style=\"text-align: center;\">   0.0    </td><td style=\"text-align: center;\">   3.9   </td><td style=\"text-align: center;\">    3.9    </td></tr>\\n<tr><td style=\"text-align: center;\">     2     </td><td style=\"text-align: center;\">       22       </td><td style=\"text-align: center;\">     4.0      </td><td style=\"text-align: center;\">   4.0   </td><td style=\"text-align: center;\">    4.2     </td><td style=\"text-align: center;\">    0.0     </td><td style=\"text-align: center;\">    0.0    </td><td style=\"text-align: center;\">   4.0   </td><td style=\"text-align: center;\">  4.1  </td><td style=\"text-align: center;\">     4.0      </td><td style=\"text-align: center;\">  4.0  </td><td style=\"text-align: center;\">   0.0    </td><td style=\"text-align: center;\">   3.0   </td><td style=\"text-align: center;\">   4.0    </td><td style=\"text-align: center;\">   0.0    </td><td style=\"text-align: center;\">   3.9   </td><td style=\"text-align: center;\">    3.9    </td></tr>\\n</tbody>\\n</table>'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pprint_train(user_train, user_features, uvs,  u_s, maxcount=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the user and item/movie features are not used in training. In the table above, the features in brackets \"[]\" such as the \"user id\", \"rating count\" and \"rating ave\" are not included when the model is trained and used.\n",
    "Above you can see the per genre rating average for user 2. Zero entries are genre's which the user had not rated. The user vector is the same for all the movies rated by a user.  \n",
    "Let's look at the first few entries of the movie/item array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th style=\"text-align: center;\"> [movie id] </th><th style=\"text-align: center;\"> year </th><th style=\"text-align: center;\"> ave rating </th><th style=\"text-align: center;\"> Act ion </th><th style=\"text-align: center;\"> Adve nture </th><th style=\"text-align: center;\"> Anim ation </th><th style=\"text-align: center;\"> Chil dren </th><th style=\"text-align: center;\"> Com edy </th><th style=\"text-align: center;\"> Crime </th><th style=\"text-align: center;\"> Docum entary </th><th style=\"text-align: center;\"> Drama </th><th style=\"text-align: center;\"> Fan tasy </th><th style=\"text-align: center;\"> Hor ror </th><th style=\"text-align: center;\"> Mys tery </th><th style=\"text-align: center;\"> Rom ance </th><th style=\"text-align: center;\"> Sci -Fi </th><th style=\"text-align: center;\"> Thri ller </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: center;\">    6874    </td><td style=\"text-align: center;\"> 2003 </td><td style=\"text-align: center;\">    4.0     </td><td style=\"text-align: center;\">    1    </td><td style=\"text-align: center;\">     0      </td><td style=\"text-align: center;\">     0      </td><td style=\"text-align: center;\">     0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">   1   </td><td style=\"text-align: center;\">      0       </td><td style=\"text-align: center;\">   0   </td><td style=\"text-align: center;\">    0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">    0     </td><td style=\"text-align: center;\">    0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">     1     </td></tr>\n",
       "<tr><td style=\"text-align: center;\">    8798    </td><td style=\"text-align: center;\"> 2004 </td><td style=\"text-align: center;\">    3.8     </td><td style=\"text-align: center;\">    1    </td><td style=\"text-align: center;\">     0      </td><td style=\"text-align: center;\">     0      </td><td style=\"text-align: center;\">     0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">   1   </td><td style=\"text-align: center;\">      0       </td><td style=\"text-align: center;\">   1   </td><td style=\"text-align: center;\">    0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">    0     </td><td style=\"text-align: center;\">    0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">     1     </td></tr>\n",
       "<tr><td style=\"text-align: center;\">   46970    </td><td style=\"text-align: center;\"> 2006 </td><td style=\"text-align: center;\">    3.2     </td><td style=\"text-align: center;\">    1    </td><td style=\"text-align: center;\">     0      </td><td style=\"text-align: center;\">     0      </td><td style=\"text-align: center;\">     0     </td><td style=\"text-align: center;\">    1    </td><td style=\"text-align: center;\">   0   </td><td style=\"text-align: center;\">      0       </td><td style=\"text-align: center;\">   0   </td><td style=\"text-align: center;\">    0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">    0     </td><td style=\"text-align: center;\">    0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">     0     </td></tr>\n",
       "<tr><td style=\"text-align: center;\">   48516    </td><td style=\"text-align: center;\"> 2006 </td><td style=\"text-align: center;\">    4.3     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">     0      </td><td style=\"text-align: center;\">     0      </td><td style=\"text-align: center;\">     0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">   1   </td><td style=\"text-align: center;\">      0       </td><td style=\"text-align: center;\">   1   </td><td style=\"text-align: center;\">    0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">    0     </td><td style=\"text-align: center;\">    0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">     1     </td></tr>\n",
       "<tr><td style=\"text-align: center;\">   58559    </td><td style=\"text-align: center;\"> 2008 </td><td style=\"text-align: center;\">    4.2     </td><td style=\"text-align: center;\">    1    </td><td style=\"text-align: center;\">     0      </td><td style=\"text-align: center;\">     0      </td><td style=\"text-align: center;\">     0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">   1   </td><td style=\"text-align: center;\">      0       </td><td style=\"text-align: center;\">   1   </td><td style=\"text-align: center;\">    0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">    0     </td><td style=\"text-align: center;\">    0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">     0     </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "'<table>\\n<thead>\\n<tr><th style=\"text-align: center;\"> [movie id] </th><th style=\"text-align: center;\"> year </th><th style=\"text-align: center;\"> ave rating </th><th style=\"text-align: center;\"> Act ion </th><th style=\"text-align: center;\"> Adve nture </th><th style=\"text-align: center;\"> Anim ation </th><th style=\"text-align: center;\"> Chil dren </th><th style=\"text-align: center;\"> Com edy </th><th style=\"text-align: center;\"> Crime </th><th style=\"text-align: center;\"> Docum entary </th><th style=\"text-align: center;\"> Drama </th><th style=\"text-align: center;\"> Fan tasy </th><th style=\"text-align: center;\"> Hor ror </th><th style=\"text-align: center;\"> Mys tery </th><th style=\"text-align: center;\"> Rom ance </th><th style=\"text-align: center;\"> Sci -Fi </th><th style=\"text-align: center;\"> Thri ller </th></tr>\\n</thead>\\n<tbody>\\n<tr><td style=\"text-align: center;\">    6874    </td><td style=\"text-align: center;\"> 2003 </td><td style=\"text-align: center;\">    4.0     </td><td style=\"text-align: center;\">    1    </td><td style=\"text-align: center;\">     0      </td><td style=\"text-align: center;\">     0      </td><td style=\"text-align: center;\">     0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">   1   </td><td style=\"text-align: center;\">      0       </td><td style=\"text-align: center;\">   0   </td><td style=\"text-align: center;\">    0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">    0     </td><td style=\"text-align: center;\">    0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">     1     </td></tr>\\n<tr><td style=\"text-align: center;\">    8798    </td><td style=\"text-align: center;\"> 2004 </td><td style=\"text-align: center;\">    3.8     </td><td style=\"text-align: center;\">    1    </td><td style=\"text-align: center;\">     0      </td><td style=\"text-align: center;\">     0      </td><td style=\"text-align: center;\">     0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">   1   </td><td style=\"text-align: center;\">      0       </td><td style=\"text-align: center;\">   1   </td><td style=\"text-align: center;\">    0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">    0     </td><td style=\"text-align: center;\">    0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">     1     </td></tr>\\n<tr><td style=\"text-align: center;\">   46970    </td><td style=\"text-align: center;\"> 2006 </td><td style=\"text-align: center;\">    3.2     </td><td style=\"text-align: center;\">    1    </td><td style=\"text-align: center;\">     0      </td><td style=\"text-align: center;\">     0      </td><td style=\"text-align: center;\">     0     </td><td style=\"text-align: center;\">    1    </td><td style=\"text-align: center;\">   0   </td><td style=\"text-align: center;\">      0       </td><td style=\"text-align: center;\">   0   </td><td style=\"text-align: center;\">    0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">    0     </td><td style=\"text-align: center;\">    0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">     0     </td></tr>\\n<tr><td style=\"text-align: center;\">   48516    </td><td style=\"text-align: center;\"> 2006 </td><td style=\"text-align: center;\">    4.3     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">     0      </td><td style=\"text-align: center;\">     0      </td><td style=\"text-align: center;\">     0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">   1   </td><td style=\"text-align: center;\">      0       </td><td style=\"text-align: center;\">   1   </td><td style=\"text-align: center;\">    0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">    0     </td><td style=\"text-align: center;\">    0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">     1     </td></tr>\\n<tr><td style=\"text-align: center;\">   58559    </td><td style=\"text-align: center;\"> 2008 </td><td style=\"text-align: center;\">    4.2     </td><td style=\"text-align: center;\">    1    </td><td style=\"text-align: center;\">     0      </td><td style=\"text-align: center;\">     0      </td><td style=\"text-align: center;\">     0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">   1   </td><td style=\"text-align: center;\">      0       </td><td style=\"text-align: center;\">   1   </td><td style=\"text-align: center;\">    0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">    0     </td><td style=\"text-align: center;\">    0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">     0     </td></tr>\\n</tbody>\\n</table>'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pprint_train(item_train, item_features, ivs, i_s, maxcount=5, user=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, the movie array contains the year the film was released, the average rating and an indicator for each potential genre. The indicator is one for each genre that applies to the movie. The movie id is not used in training but is useful when interpreting the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train[:5]: [4.  3.5 4.  4.  4.5]\n"
     ]
    }
   ],
   "source": [
    "print(f\"y_train[:5]: {y_train[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target, y, is the movie rating given by the user. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we can see that movie 6874 is an Action/Crime/Thriller movie released in 2003. User 2 rates action movies as 3.9 on average. MovieLens users gave the movie an average rating of 4. 'y' is 4 indicating user 2 rated movie 6874 as a 4 as well. A single training example consists of a row from both the user and item arrays and a rating from y_train."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"3.2\"></a>\n",
    "### 3.2 Preparing the training data\n",
    "Recall in Course 1, Week 2, you explored feature scaling as a means of improving convergence. We'll scale the input features using the [scikit learn StandardScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html). This was used in Course 1, Week 2, Lab 5.  Below, the inverse_transform is also shown to produce the original inputs. We'll scale the target ratings using a Min Max Scaler which scales the target to be between -1 and 1. [scikit learn MinMaxScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# scale training data\n",
    "item_train_unscaled = item_train\n",
    "user_train_unscaled = user_train\n",
    "y_train_unscaled    = y_train\n",
    "\n",
    "scalerItem = StandardScaler()\n",
    "item_train = scalerItem.fit_transform(item_train)\n",
    "'''\n",
    "StandardScaler(): This is a class from the sklearn.preprocessing module, which is used to standardize or normalize the features of your data.\n",
    "Standardization means scaling your data such that it has:\n",
    "A mean of 0.\n",
    "A standard deviation of 1.\n",
    "scalerItem: This is an instance of the StandardScaler class. It will later be used to fit to your data and transform it (i.e., standardize it).\n",
    "fit_transform() is a combined method that:\n",
    "fit(): Calculates the mean and standard deviation of each feature (column) in the input data (item_train), using the training data.\n",
    "This is done for each column in the data (i.e., feature-wise).\n",
    "transform(): Then scales the data by subtracting the mean and dividing by the standard deviation, so that:\n",
    "Each feature in the dataset has a mean of 0.\n",
    "Each feature has a standard deviation of 1.\n",
    "item_train: This is the transformed data where the features have been standardized.\n",
    "'''\n",
    "\n",
    "scalerUser = StandardScaler()\n",
    "user_train = scalerUser.fit_transform(user_train)\n",
    "\n",
    "scalerTarget = MinMaxScaler((-1, 1))  # Set the range from -1 to 1\n",
    "y_train = scalerTarget.fit_transform(y_train.reshape(-1, 1))  # Fit and transform in one step\n",
    "'''\n",
    "MinMaxScaler: This is a class from sklearn.preprocessing that scales data to a given range. By default, it scales the data to a range of 0 to 1, but here we specify (-1, 1) as the desired range.\n",
    "(-1, 1): This means that the smallest value in your data will be scaled to -1, and the largest value will be scaled to 1. All the values in between will be scaled proportionally.\n",
    "scalerTarget: This is an instance of the MinMaxScaler initialized with the range (-1, 1). It's ready to be used to scale your data.\n",
    "fit_transform(): This is a combination of two methods: fit() and transform() in one step. Here's how they work:\n",
    "fit(): The fit() method computes the minimum and maximum values of the data. It uses y_train.reshape(-1, 1) to convert y_train into a 2D array (required by the MinMaxScaler).\n",
    "transform(): After fitting, transform() scales the data based on the min and max values that were calculated during the fit() step. It scales each value in y_train to be between -1 and 1.\n",
    "reshape(-1, 1): This reshapes the 1D array y_train (which has shape (n,)) into a 2D array with shape (n, 1). This is necessary because MinMaxScaler expects a 2D array (i.e., a matrix) for scaling.\n",
    "The result: The scaled data is stored back in y_train. After this line, y_train contains values that are scaled between -1 and 1.\n",
    "'''\n",
    "#ynorm_test = scalerTarget.transform(y_test.reshape(-1, 1))\n",
    "\n",
    "print(np.allclose(item_train_unscaled, scalerItem.inverse_transform(item_train))) #is used to check whether the transformation and the inverse transformation of item_train match the original unscaled data (item_train_unscaled).\n",
    "'''\n",
    "scalerItem.inverse_transform(item_train):\n",
    "The inverse_transform() method reverses the scaling operation that was applied earlier by the StandardScaler.\n",
    "This method restores the original values (or close to it) by applying the inverse of the scaling transformation. Specifically, it applies:\n",
    "ð‘¥_original = ð‘¥_scaled Ã— std + mean\n",
    "where std and mean are the values learned by StandardScaler during the fit() step.\n",
    "np.allclose():\n",
    "This function checks whether two arrays are element-wise equal within a tolerance. It is used here to check if the restored values from the inverse transformation are close enough to the original unscaled values (item_train_unscaled).\n",
    "It returns True if the arrays are equal within the specified tolerance, and False if they are not.\n",
    "Purpose:\n",
    "The goal of this code is to confirm that the inverse transformation has successfully restored the original data. If np.allclose() returns True, it means that the scaling and inverse scaling process has worked correctly, and the data matches.\n",
    "If it returns False, there might be a discrepancy between the original and restored data, indicating an issue in the transformation process (e.g., incorrect scaling, or the unscaled data might not match exactly due to floating-point precision).\n",
    "'''\n",
    "print(np.allclose(user_train_unscaled, scalerUser.inverse_transform(user_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To allow us to evaluate the results, we will split the data into training and test sets as was discussed in Course 2, Week 3. Here we will use [sklean train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) to split and shuffle the data. Note that setting the initial random state to the same value ensures item, user, and y are shuffled identically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movie/item training data shape: (40707, 17)\n",
      "movie/item test data shape: (10177, 17)\n",
      "user training data shape: (40707, 17)\n",
      "user test data shape: (10177, 17)\n"
     ]
    }
   ],
   "source": [
    "item_train, item_test = train_test_split(item_train, train_size=0.80, shuffle=True, random_state=1)\n",
    "'''\n",
    "Explanation of Arguments:\n",
    "item_train:\n",
    "This is the dataset you want to split. It could be a NumPy array, pandas DataFrame, or any other data structure containing your data.\n",
    "train_size=0.80:\n",
    "This specifies the proportion of the data to include in the training set. Here, 80% of the data (0.80) will be used for training, and the remaining 20% will be used for testing.\n",
    "shuffle=True:\n",
    "This argument ensures that the data is shuffled randomly before splitting. If set to True, the data will be shuffled before splitting into train and test sets.\n",
    "This is useful to ensure that the data is randomly distributed and that the model doesn't learn any patterns based on the order of the data (which might lead to bias).\n",
    "random_state=1:\n",
    "This is the random seed used for reproducibility. It ensures that every time you run the code with the same data, you get the same random split.\n",
    "Setting random_state=1 guarantees that the shuffle operation will be deterministic, i.e., the split will be the same every time the code is run.\n",
    "'''\n",
    "user_train, user_test = train_test_split(user_train, train_size=0.80, shuffle=True, random_state=1)\n",
    "y_train, y_test       = train_test_split(y_train,    train_size=0.80, shuffle=True, random_state=1)\n",
    "print(f\"movie/item training data shape: {item_train.shape}\")\n",
    "print(f\"movie/item test data shape: {item_test.shape}\")\n",
    "\n",
    "print(f\"user training data shape: {user_train.shape}\")\n",
    "print(f\"user test data shape: {user_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scaled, shuffled data now has a mean of zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th style=\"text-align: center;\"> [user id] </th><th style=\"text-align: center;\"> [rating count] </th><th style=\"text-align: center;\"> [rating ave] </th><th style=\"text-align: center;\"> Act ion </th><th style=\"text-align: center;\"> Adve nture </th><th style=\"text-align: center;\"> Anim ation </th><th style=\"text-align: center;\"> Chil dren </th><th style=\"text-align: center;\"> Com edy </th><th style=\"text-align: center;\"> Crime </th><th style=\"text-align: center;\"> Docum entary </th><th style=\"text-align: center;\"> Drama </th><th style=\"text-align: center;\"> Fan tasy </th><th style=\"text-align: center;\"> Hor ror </th><th style=\"text-align: center;\"> Mys tery </th><th style=\"text-align: center;\"> Rom ance </th><th style=\"text-align: center;\"> Sci -Fi </th><th style=\"text-align: center;\"> Thri ller </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: center;\">     1     </td><td style=\"text-align: center;\">       0        </td><td style=\"text-align: center;\">     -1.0     </td><td style=\"text-align: center;\">  -0.8   </td><td style=\"text-align: center;\">    -0.7    </td><td style=\"text-align: center;\">    0.1     </td><td style=\"text-align: center;\">   -0.0    </td><td style=\"text-align: center;\">  -1.2   </td><td style=\"text-align: center;\"> -0.4  </td><td style=\"text-align: center;\">     0.6      </td><td style=\"text-align: center;\"> -0.5  </td><td style=\"text-align: center;\">   -0.5   </td><td style=\"text-align: center;\">  -0.1   </td><td style=\"text-align: center;\">   -0.6   </td><td style=\"text-align: center;\">   -0.6   </td><td style=\"text-align: center;\">  -0.7   </td><td style=\"text-align: center;\">   -0.7    </td></tr>\n",
       "<tr><td style=\"text-align: center;\">     0     </td><td style=\"text-align: center;\">       1        </td><td style=\"text-align: center;\">     -0.7     </td><td style=\"text-align: center;\">  -0.5   </td><td style=\"text-align: center;\">    -0.7    </td><td style=\"text-align: center;\">    -0.1    </td><td style=\"text-align: center;\">   -0.2    </td><td style=\"text-align: center;\">  -0.6   </td><td style=\"text-align: center;\"> -0.2  </td><td style=\"text-align: center;\">     0.7      </td><td style=\"text-align: center;\"> -0.5  </td><td style=\"text-align: center;\">   -0.8   </td><td style=\"text-align: center;\">   0.1   </td><td style=\"text-align: center;\">   -0.0   </td><td style=\"text-align: center;\">   -0.6   </td><td style=\"text-align: center;\">  -0.5   </td><td style=\"text-align: center;\">   -0.4    </td></tr>\n",
       "<tr><td style=\"text-align: center;\">    -1     </td><td style=\"text-align: center;\">       -1       </td><td style=\"text-align: center;\">     -0.2     </td><td style=\"text-align: center;\">   0.3   </td><td style=\"text-align: center;\">    -0.4    </td><td style=\"text-align: center;\">    0.4     </td><td style=\"text-align: center;\">    0.5    </td><td style=\"text-align: center;\">   1.0   </td><td style=\"text-align: center;\">  0.6  </td><td style=\"text-align: center;\">     -1.2     </td><td style=\"text-align: center;\"> -0.3  </td><td style=\"text-align: center;\">   -0.6   </td><td style=\"text-align: center;\">  -2.3   </td><td style=\"text-align: center;\">   -0.1   </td><td style=\"text-align: center;\">   0.0    </td><td style=\"text-align: center;\">   0.4   </td><td style=\"text-align: center;\">   -0.0    </td></tr>\n",
       "<tr><td style=\"text-align: center;\">     0     </td><td style=\"text-align: center;\">       -1       </td><td style=\"text-align: center;\">     0.6      </td><td style=\"text-align: center;\">   0.5   </td><td style=\"text-align: center;\">    0.5     </td><td style=\"text-align: center;\">    0.2     </td><td style=\"text-align: center;\">    0.6    </td><td style=\"text-align: center;\">  -0.1   </td><td style=\"text-align: center;\">  0.5  </td><td style=\"text-align: center;\">     -1.2     </td><td style=\"text-align: center;\">  0.9  </td><td style=\"text-align: center;\">   1.2    </td><td style=\"text-align: center;\">  -2.3   </td><td style=\"text-align: center;\">   -0.1   </td><td style=\"text-align: center;\">   0.0    </td><td style=\"text-align: center;\">   0.2   </td><td style=\"text-align: center;\">    0.3    </td></tr>\n",
       "<tr><td style=\"text-align: center;\">    -1     </td><td style=\"text-align: center;\">       0        </td><td style=\"text-align: center;\">     0.7      </td><td style=\"text-align: center;\">   0.6   </td><td style=\"text-align: center;\">    0.5     </td><td style=\"text-align: center;\">    0.3     </td><td style=\"text-align: center;\">    0.5    </td><td style=\"text-align: center;\">   0.4   </td><td style=\"text-align: center;\">  0.6  </td><td style=\"text-align: center;\">     1.0      </td><td style=\"text-align: center;\">  0.6  </td><td style=\"text-align: center;\">   0.3    </td><td style=\"text-align: center;\">   0.8   </td><td style=\"text-align: center;\">   0.8    </td><td style=\"text-align: center;\">   0.4    </td><td style=\"text-align: center;\">   0.7   </td><td style=\"text-align: center;\">    0.7    </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "'<table>\\n<thead>\\n<tr><th style=\"text-align: center;\"> [user id] </th><th style=\"text-align: center;\"> [rating count] </th><th style=\"text-align: center;\"> [rating ave] </th><th style=\"text-align: center;\"> Act ion </th><th style=\"text-align: center;\"> Adve nture </th><th style=\"text-align: center;\"> Anim ation </th><th style=\"text-align: center;\"> Chil dren </th><th style=\"text-align: center;\"> Com edy </th><th style=\"text-align: center;\"> Crime </th><th style=\"text-align: center;\"> Docum entary </th><th style=\"text-align: center;\"> Drama </th><th style=\"text-align: center;\"> Fan tasy </th><th style=\"text-align: center;\"> Hor ror </th><th style=\"text-align: center;\"> Mys tery </th><th style=\"text-align: center;\"> Rom ance </th><th style=\"text-align: center;\"> Sci -Fi </th><th style=\"text-align: center;\"> Thri ller </th></tr>\\n</thead>\\n<tbody>\\n<tr><td style=\"text-align: center;\">     1     </td><td style=\"text-align: center;\">       0        </td><td style=\"text-align: center;\">     -1.0     </td><td style=\"text-align: center;\">  -0.8   </td><td style=\"text-align: center;\">    -0.7    </td><td style=\"text-align: center;\">    0.1     </td><td style=\"text-align: center;\">   -0.0    </td><td style=\"text-align: center;\">  -1.2   </td><td style=\"text-align: center;\"> -0.4  </td><td style=\"text-align: center;\">     0.6      </td><td style=\"text-align: center;\"> -0.5  </td><td style=\"text-align: center;\">   -0.5   </td><td style=\"text-align: center;\">  -0.1   </td><td style=\"text-align: center;\">   -0.6   </td><td style=\"text-align: center;\">   -0.6   </td><td style=\"text-align: center;\">  -0.7   </td><td style=\"text-align: center;\">   -0.7    </td></tr>\\n<tr><td style=\"text-align: center;\">     0     </td><td style=\"text-align: center;\">       1        </td><td style=\"text-align: center;\">     -0.7     </td><td style=\"text-align: center;\">  -0.5   </td><td style=\"text-align: center;\">    -0.7    </td><td style=\"text-align: center;\">    -0.1    </td><td style=\"text-align: center;\">   -0.2    </td><td style=\"text-align: center;\">  -0.6   </td><td style=\"text-align: center;\"> -0.2  </td><td style=\"text-align: center;\">     0.7      </td><td style=\"text-align: center;\"> -0.5  </td><td style=\"text-align: center;\">   -0.8   </td><td style=\"text-align: center;\">   0.1   </td><td style=\"text-align: center;\">   -0.0   </td><td style=\"text-align: center;\">   -0.6   </td><td style=\"text-align: center;\">  -0.5   </td><td style=\"text-align: center;\">   -0.4    </td></tr>\\n<tr><td style=\"text-align: center;\">    -1     </td><td style=\"text-align: center;\">       -1       </td><td style=\"text-align: center;\">     -0.2     </td><td style=\"text-align: center;\">   0.3   </td><td style=\"text-align: center;\">    -0.4    </td><td style=\"text-align: center;\">    0.4     </td><td style=\"text-align: center;\">    0.5    </td><td style=\"text-align: center;\">   1.0   </td><td style=\"text-align: center;\">  0.6  </td><td style=\"text-align: center;\">     -1.2     </td><td style=\"text-align: center;\"> -0.3  </td><td style=\"text-align: center;\">   -0.6   </td><td style=\"text-align: center;\">  -2.3   </td><td style=\"text-align: center;\">   -0.1   </td><td style=\"text-align: center;\">   0.0    </td><td style=\"text-align: center;\">   0.4   </td><td style=\"text-align: center;\">   -0.0    </td></tr>\\n<tr><td style=\"text-align: center;\">     0     </td><td style=\"text-align: center;\">       -1       </td><td style=\"text-align: center;\">     0.6      </td><td style=\"text-align: center;\">   0.5   </td><td style=\"text-align: center;\">    0.5     </td><td style=\"text-align: center;\">    0.2     </td><td style=\"text-align: center;\">    0.6    </td><td style=\"text-align: center;\">  -0.1   </td><td style=\"text-align: center;\">  0.5  </td><td style=\"text-align: center;\">     -1.2     </td><td style=\"text-align: center;\">  0.9  </td><td style=\"text-align: center;\">   1.2    </td><td style=\"text-align: center;\">  -2.3   </td><td style=\"text-align: center;\">   -0.1   </td><td style=\"text-align: center;\">   0.0    </td><td style=\"text-align: center;\">   0.2   </td><td style=\"text-align: center;\">    0.3    </td></tr>\\n<tr><td style=\"text-align: center;\">    -1     </td><td style=\"text-align: center;\">       0        </td><td style=\"text-align: center;\">     0.7      </td><td style=\"text-align: center;\">   0.6   </td><td style=\"text-align: center;\">    0.5     </td><td style=\"text-align: center;\">    0.3     </td><td style=\"text-align: center;\">    0.5    </td><td style=\"text-align: center;\">   0.4   </td><td style=\"text-align: center;\">  0.6  </td><td style=\"text-align: center;\">     1.0      </td><td style=\"text-align: center;\">  0.6  </td><td style=\"text-align: center;\">   0.3    </td><td style=\"text-align: center;\">   0.8   </td><td style=\"text-align: center;\">   0.8    </td><td style=\"text-align: center;\">   0.4    </td><td style=\"text-align: center;\">   0.7   </td><td style=\"text-align: center;\">    0.7    </td></tr>\\n</tbody>\\n</table>'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pprint_train(user_train, user_features, uvs, u_s, maxcount=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"4\"></a>\n",
    "## 4 - Neural Network for content-based filtering\n",
    "Now, let's construct a neural network as described in the figure above. It will have two networks that are combined by a dot product. You will construct the two networks. In this example, they will be identical. Note that these networks do not need to be the same. If the user content was substantially larger than the movie content, you might elect to increase the complexity of the user network relative to the movie network. In this case, the content is similar, so the networks are the same.\n",
    "\n",
    "<a name=\"ex01\"></a>\n",
    "### Exercise 1\n",
    "\n",
    "- Use a Keras sequential model\n",
    "    - The first layer is a dense layer with 256 units and a relu activation.\n",
    "    - The second layer is a dense layer with 128 units and a relu activation.\n",
    "    - The third layer is a dense layer with `num_outputs` units and a linear or no activation.   \n",
    "    \n",
    "The remainder of the network will be provided. The provided code does not use the Keras sequential model but instead uses the Keras [functional api](https://keras.io/guides/functional_api/). This format allows for more flexibility in how components are interconnected.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "id": "CBjZ2HhRwpa0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 32)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)        </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape      </span>â”ƒ<span style=\"font-weight: bold\">    Param # </span>â”ƒ<span style=\"font-weight: bold\"> Connected to      </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ input_layer         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ input_layer_2       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ sequential          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">40,864</span> â”‚ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ sequential_1        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">41,376</span> â”‚ input_layer_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]â€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ lambda (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ sequential[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ lambda_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ sequential_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dot (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dot</span>)           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ lambda[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     â”‚\n",
       "â”‚                     â”‚                   â”‚            â”‚ lambda_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ input_layer         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
       "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ input_layer_2       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
       "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ sequential          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚     \u001b[38;5;34m40,864\u001b[0m â”‚ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] â”‚\n",
       "â”‚ (\u001b[38;5;33mSequential\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ sequential_1        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚     \u001b[38;5;34m41,376\u001b[0m â”‚ input_layer_2[\u001b[38;5;34m0\u001b[0m]â€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mSequential\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ lambda (\u001b[38;5;33mLambda\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ sequential[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ lambda_1 (\u001b[38;5;33mLambda\u001b[0m)   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ sequential_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dot (\u001b[38;5;33mDot\u001b[0m)           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         â”‚          \u001b[38;5;34m0\u001b[0m â”‚ lambda[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     â”‚\n",
       "â”‚                     â”‚                   â”‚            â”‚ lambda_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">82,240</span> (321.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m82,240\u001b[0m (321.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">82,240</span> (321.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m82,240\u001b[0m (321.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# GRADED_CELL\n",
    "# UNQ_C1\n",
    "from tensorflow.keras.layers import Lambda\n",
    "\n",
    "num_outputs = 32\n",
    "num_user_features = user_train.shape[1] - 3\n",
    "tf.random.set_seed(1)\n",
    "user_NN = tf.keras.models.Sequential([\n",
    "    ### START CODE HERE ###   \n",
    "    tf.keras.layers.Dense(units = 256, activation='relu'),\n",
    "    tf.keras.layers.Dense(units = 128, activation='relu'),\n",
    "    tf.keras.layers.Dense(units = num_outputs, activation='linear'),\n",
    "    ### END CODE HERE ###  \n",
    "])\n",
    "\n",
    "item_NN = tf.keras.models.Sequential([\n",
    "    ### START CODE HERE ###     \n",
    "    tf.keras.layers.Dense(units = 256, activation='relu'),\n",
    "    tf.keras.layers.Dense(units = 128, activation='relu'),\n",
    "    tf.keras.layers.Dense(units = num_outputs, activation='linear'),  \n",
    "    ### END CODE HERE ###  \n",
    "])\n",
    "\n",
    "# create the user input and point to the base network\n",
    "input_user = tf.keras.layers.Input(shape=(num_user_features,))\n",
    "# vu = user_NN(input_user)\n",
    "# vu = tf.linalg.l2_normalize(vu, axis=1)\n",
    "# Instead of using tf.linalg.l2_normalize, use L2Normalization layer\n",
    "# Create user input layer\n",
    "vu = user_NN(input_user)\n",
    "\n",
    "# Normalize the output using L2 Normalization (using Lambda layer)\n",
    "vu = Lambda(lambda x: tf.nn.l2_normalize(x, axis=1))(vu)\n",
    "\n",
    "# create the item input and point to the base network\n",
    "input_item = tf.keras.layers.Input(shape=(num_item_features,))\n",
    "# vm = item_NN(input_item)\n",
    "# vm = tf.linalg.l2_normalize(vm, axis=1)\n",
    "# Create user input layer\n",
    "vm = item_NN(input_item)\n",
    "\n",
    "# Normalize the output using L2 Normalization (using Lambda layer)\n",
    "vm = Lambda(lambda x: tf.nn.l2_normalize(x, axis=1))(vm)\n",
    "# compute the dot product of the two vectors vu and vm\n",
    "output = tf.keras.layers.Dot(axes=1)([vu, vm]) #The Dot(axes=1) layer computes the dot product of corresponding rows in vu and vm.\n",
    "\n",
    "# specify the inputs and output of the model\n",
    "model = tf.keras.Model([input_user, input_item], output)\n",
    "print(vm.shape)\n",
    "model.summary()\n",
    "\n",
    "# Summary of the Model Structure:\n",
    "# Input Layer: Accepts data with shape (None, 14) and (None, 16) for user and item features respectively.\n",
    "# Sequential Layers: The user and item features are passed through two fully connected layers with 32 output features each.\n",
    "# Lambda Layers: Custom transformations (like normalization) are applied to the user and item features.\n",
    "# Dot Layer: Computes the dot product of the user and item vectors to generate a similarity score or prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Public tests\n",
    "from public_tests import *\n",
    "# test_tower(user_NN)\n",
    "# test_tower(item_NN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary><font size=\"3\" color=\"darkgreen\"><b>Click for hints</b></font></summary>\n",
    "    \n",
    "  You can create a dense layer with a relu activation as shown.\n",
    "    \n",
    "```python     \n",
    "user_NN = tf.keras.models.Sequential([\n",
    "    ### START CODE HERE ###     \n",
    "  tf.keras.layers.Dense(256, activation='relu'),\n",
    "\n",
    "    \n",
    "    ### END CODE HERE ###  \n",
    "])\n",
    "\n",
    "item_NN = tf.keras.models.Sequential([\n",
    "    ### START CODE HERE ###     \n",
    "  tf.keras.layers.Dense(256, activation='relu'),\n",
    "\n",
    "    \n",
    "    ### END CODE HERE ###  \n",
    "])\n",
    "```    \n",
    "<details>\n",
    "    <summary><font size=\"2\" color=\"darkblue\"><b> Click for solution</b></font></summary>\n",
    "    \n",
    "```python \n",
    "user_NN = tf.keras.models.Sequential([\n",
    "    ### START CODE HERE ###     \n",
    "  tf.keras.layers.Dense(256, activation='relu'),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dense(num_outputs),\n",
    "    ### END CODE HERE ###  \n",
    "])\n",
    "\n",
    "item_NN = tf.keras.models.Sequential([\n",
    "    ### START CODE HERE ###     \n",
    "  tf.keras.layers.Dense(256, activation='relu'),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dense(num_outputs),\n",
    "    ### END CODE HERE ###  \n",
    "])\n",
    "```\n",
    "</details>\n",
    "</details>\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use a mean squared error loss and an Adam optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "pGK5MEUowxN4"
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(1)\n",
    "cost_fn = tf.keras.losses.MeanSquaredError()\n",
    "opt = keras.optimizers.Adam(learning_rate=0.01)\n",
    "model.compile(optimizer=opt,\n",
    "              loss=cost_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "6zHf7eASw0tN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m1273/1273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.1310\n",
      "Epoch 2/30\n",
      "\u001b[1m1273/1273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.1142\n",
      "Epoch 3/30\n",
      "\u001b[1m1273/1273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.1104\n",
      "Epoch 4/30\n",
      "\u001b[1m1273/1273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.1073\n",
      "Epoch 5/30\n",
      "\u001b[1m1273/1273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.1045\n",
      "Epoch 6/30\n",
      "\u001b[1m1273/1273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.1018\n",
      "Epoch 7/30\n",
      "\u001b[1m1273/1273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0989\n",
      "Epoch 8/30\n",
      "\u001b[1m1273/1273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0967\n",
      "Epoch 9/30\n",
      "\u001b[1m1273/1273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0946\n",
      "Epoch 10/30\n",
      "\u001b[1m1273/1273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0926\n",
      "Epoch 11/30\n",
      "\u001b[1m1273/1273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0910\n",
      "Epoch 12/30\n",
      "\u001b[1m1273/1273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0894\n",
      "Epoch 13/30\n",
      "\u001b[1m1273/1273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0881\n",
      "Epoch 14/30\n",
      "\u001b[1m1273/1273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0869\n",
      "Epoch 15/30\n",
      "\u001b[1m1273/1273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0857\n",
      "Epoch 16/30\n",
      "\u001b[1m1273/1273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0846\n",
      "Epoch 17/30\n",
      "\u001b[1m1273/1273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0835\n",
      "Epoch 18/30\n",
      "\u001b[1m1273/1273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0824\n",
      "Epoch 19/30\n",
      "\u001b[1m1273/1273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0814\n",
      "Epoch 20/30\n",
      "\u001b[1m1273/1273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0804\n",
      "Epoch 21/30\n",
      "\u001b[1m1273/1273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0795\n",
      "Epoch 22/30\n",
      "\u001b[1m1273/1273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0786\n",
      "Epoch 23/30\n",
      "\u001b[1m1273/1273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0777\n",
      "Epoch 24/30\n",
      "\u001b[1m1273/1273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0769\n",
      "Epoch 25/30\n",
      "\u001b[1m1273/1273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0761\n",
      "Epoch 26/30\n",
      "\u001b[1m1273/1273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0754\n",
      "Epoch 27/30\n",
      "\u001b[1m1273/1273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0747\n",
      "Epoch 28/30\n",
      "\u001b[1m1273/1273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0742\n",
      "Epoch 29/30\n",
      "\u001b[1m1273/1273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0735\n",
      "Epoch 30/30\n",
      "\u001b[1m1273/1273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0729\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x3154dda50>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(1)\n",
    "model.fit([user_train[:, u_s:], item_train[:, i_s:]], y_train, epochs=30) #This is the function that trains the model on your data.\n",
    "'''\n",
    "Breakdown of model.fit():\n",
    "    model: The Keras model that you are training. It should already be defined and compiled.\n",
    "user_train[:, u_s:] and item_train[:, i_s:]:\n",
    "    user_train and item_train are the training datasets for the user and item features, respectively. These datasets are likely matrices or 2D arrays where each row corresponds to a sample, and each column corresponds to a feature.\n",
    "    Slicing: The notation [:, u_s:] means \"take all rows and from column u_s onwards\", i.e., you are selecting a subset of the columns starting from index u_s for user_train, and similarly from index i_s for item_train.\n",
    "    Why slicing?: It's likely that user_train and item_train contain different sets of features for the user and item, and you're selecting a specific part of those features that corresponds to the features needed for training.\n",
    "    u_s and i_s: These are the starting column indices for the user and item features, respectively. They are parameters that indicate where to start selecting the columns for training.\n",
    "y_train: This is the target variable (labels) for the training set. It corresponds to the actual values you are trying to predict.\n",
    "epochs=30: The number of epochs specifies how many times the entire dataset is passed through the model during training.\n",
    "    Epoch: One epoch means that every sample in the dataset has been used once to update the model's weights.\n",
    "    30 epochs means that the model will iterate 30 times over the entire training dataset to learn the patterns.\n",
    "\n",
    "How the training works in this case:\n",
    "    The model is trained using the training data provided by user_train and item_train (with columns sliced by u_s and i_s respectively) as inputs and y_train as the target.\n",
    "    The training runs for 30 epochs, meaning the model will update its parameters after seeing the entire training data 30 times.\n",
    "\n",
    "The fit() method updates the model's internal weights using backpropagation and gradient descent during each epoch based on the loss calculated from the difference between the model's predictions and y_train.\n",
    "\n",
    "Summary:\n",
    "tf.random.set_seed(1) ensures reproducibility.\n",
    "model.fit() trains the model for 30 epochs using the user and item data (with specific columns selected using slicing), and y_train as the target labels.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model to determine loss on the test data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m319/319\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 605us/step - loss: 0.0879\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.08472093939781189"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate([user_test[:, u_s:], item_test[:, i_s:]], y_test)\n",
    "'''\n",
    "model.evaluate() is used to evaluate the performance of the trained model on the test set. It computes the loss and any additional metrics specified when compiling the model. This is typically done after training is complete, to understand how well the model is performing on unseen data (test data).\n",
    "What model.evaluate() does:\n",
    "    The method computes the loss (such as Mean Squared Error, Binary Cross-Entropy, etc.) and any other metrics that were specified during model compilation (like accuracy, precision, etc.) on the test set.\n",
    "    It returns the loss value and metrics, which help you understand how well the model generalizes to unseen data.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loss: 0.0879 is the loss calculated during evaluation on the test set.\n",
    "\n",
    "0.0847... is the final reported loss value, which is slightly more precise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is comparable to the training loss indicating the model has not substantially overfit the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xsre-gquwEls"
   },
   "source": [
    "<a name=\"5\"></a>\n",
    "## 5 - Predictions\n",
    "Below, you'll use your model to make predictions in a number of circumstances. \n",
    "<a name=\"5.1\"></a>\n",
    "### 5.1 - Predictions for a new user\n",
    "First, we'll create a new user and have the model suggest movies for that user. After you have tried this on the example user content, feel free to change the user content to match your own preferences and see what the model suggests. Note that ratings are between 0.5 and 5.0, inclusive, in half-step increments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "id": "4_7nZyPiVJ4r"
   },
   "outputs": [],
   "source": [
    "new_user_id = 5000\n",
    "new_rating_ave = 0.0\n",
    "new_action = 0.0\n",
    "new_adventure = 5.0\n",
    "new_animation = 0.0\n",
    "new_childrens = 0.0\n",
    "new_comedy = 0.0\n",
    "new_crime = 0.0\n",
    "new_documentary = 0.0\n",
    "new_drama = 0.0\n",
    "new_fantasy = 5.0\n",
    "new_horror = 0.0\n",
    "new_mystery = 0.0\n",
    "new_romance = 0.0\n",
    "new_scifi = 0.0\n",
    "new_thriller = 0.0\n",
    "new_rating_count = 3\n",
    "\n",
    "user_vec = np.array([[new_user_id, new_rating_count, new_rating_ave,\n",
    "                      new_action, new_adventure, new_animation, new_childrens,\n",
    "                      new_comedy, new_crime, new_documentary,\n",
    "                      new_drama, new_fantasy, new_horror, new_mystery,\n",
    "                      new_romance, new_scifi, new_thriller]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new user enjoys movies from the adventure, fantasy genres. Let's find the top-rated movies for the new user.  \n",
    "Below, we'll use a set of movie/item vectors, `item_vecs` that have a vector for each movie in the training/test set. This is matched with the new user vector above and the scaled vectors are used to predict ratings for all the movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th style=\"text-align: right;\">  y_p</th><th style=\"text-align: right;\">  movie id</th><th style=\"text-align: right;\">  rating ave</th><th>title                                                        </th><th>genres                         </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: right;\">  4.2</td><td style=\"text-align: right;\">     54001</td><td style=\"text-align: right;\">         3.9</td><td>Harry Potter and the Order of the Phoenix (2007)             </td><td>Adventure|Drama|Fantasy        </td></tr>\n",
       "<tr><td style=\"text-align: right;\">  4.2</td><td style=\"text-align: right;\">      8368</td><td style=\"text-align: right;\">         3.9</td><td>Harry Potter and the Prisoner of Azkaban (2004)              </td><td>Adventure|Fantasy              </td></tr>\n",
       "<tr><td style=\"text-align: right;\">  4.2</td><td style=\"text-align: right;\">      6539</td><td style=\"text-align: right;\">         3.8</td><td>Pirates of the Caribbean: The Curse of the Black Pearl (2003)</td><td>Action|Adventure|Comedy|Fantasy</td></tr>\n",
       "<tr><td style=\"text-align: right;\">  4.2</td><td style=\"text-align: right;\">     59387</td><td style=\"text-align: right;\">         4  </td><td>Fall, The (2006)                                             </td><td>Adventure|Drama|Fantasy        </td></tr>\n",
       "<tr><td style=\"text-align: right;\">  4.1</td><td style=\"text-align: right;\">     81834</td><td style=\"text-align: right;\">         4  </td><td>Harry Potter and the Deathly Hallows: Part 1 (2010)          </td><td>Action|Adventure|Fantasy       </td></tr>\n",
       "<tr><td style=\"text-align: right;\">  4.1</td><td style=\"text-align: right;\">     98809</td><td style=\"text-align: right;\">         3.8</td><td>Hobbit: An Unexpected Journey, The (2012)                    </td><td>Adventure|Fantasy              </td></tr>\n",
       "<tr><td style=\"text-align: right;\">  4.1</td><td style=\"text-align: right;\">     40815</td><td style=\"text-align: right;\">         3.8</td><td>Harry Potter and the Goblet of Fire (2005)                   </td><td>Adventure|Fantasy|Thriller     </td></tr>\n",
       "<tr><td style=\"text-align: right;\">  4.1</td><td style=\"text-align: right;\">      5816</td><td style=\"text-align: right;\">         3.6</td><td>Harry Potter and the Chamber of Secrets (2002)               </td><td>Adventure|Fantasy              </td></tr>\n",
       "<tr><td style=\"text-align: right;\">  4.1</td><td style=\"text-align: right;\">      5952</td><td style=\"text-align: right;\">         4  </td><td>Lord of the Rings: The Two Towers, The (2002)                </td><td>Adventure|Fantasy              </td></tr>\n",
       "<tr><td style=\"text-align: right;\">  4.1</td><td style=\"text-align: right;\">    106489</td><td style=\"text-align: right;\">         3.6</td><td>Hobbit: The Desolation of Smaug, The (2013)                  </td><td>Adventure|Fantasy              </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "'<table>\\n<thead>\\n<tr><th style=\"text-align: right;\">  y_p</th><th style=\"text-align: right;\">  movie id</th><th style=\"text-align: right;\">  rating ave</th><th>title                                                        </th><th>genres                         </th></tr>\\n</thead>\\n<tbody>\\n<tr><td style=\"text-align: right;\">  4.2</td><td style=\"text-align: right;\">     54001</td><td style=\"text-align: right;\">         3.9</td><td>Harry Potter and the Order of the Phoenix (2007)             </td><td>Adventure|Drama|Fantasy        </td></tr>\\n<tr><td style=\"text-align: right;\">  4.2</td><td style=\"text-align: right;\">      8368</td><td style=\"text-align: right;\">         3.9</td><td>Harry Potter and the Prisoner of Azkaban (2004)              </td><td>Adventure|Fantasy              </td></tr>\\n<tr><td style=\"text-align: right;\">  4.2</td><td style=\"text-align: right;\">      6539</td><td style=\"text-align: right;\">         3.8</td><td>Pirates of the Caribbean: The Curse of the Black Pearl (2003)</td><td>Action|Adventure|Comedy|Fantasy</td></tr>\\n<tr><td style=\"text-align: right;\">  4.2</td><td style=\"text-align: right;\">     59387</td><td style=\"text-align: right;\">         4  </td><td>Fall, The (2006)                                             </td><td>Adventure|Drama|Fantasy        </td></tr>\\n<tr><td style=\"text-align: right;\">  4.1</td><td style=\"text-align: right;\">     81834</td><td style=\"text-align: right;\">         4  </td><td>Harry Potter and the Deathly Hallows: Part 1 (2010)          </td><td>Action|Adventure|Fantasy       </td></tr>\\n<tr><td style=\"text-align: right;\">  4.1</td><td style=\"text-align: right;\">     98809</td><td style=\"text-align: right;\">         3.8</td><td>Hobbit: An Unexpected Journey, The (2012)                    </td><td>Adventure|Fantasy              </td></tr>\\n<tr><td style=\"text-align: right;\">  4.1</td><td style=\"text-align: right;\">     40815</td><td style=\"text-align: right;\">         3.8</td><td>Harry Potter and the Goblet of Fire (2005)                   </td><td>Adventure|Fantasy|Thriller     </td></tr>\\n<tr><td style=\"text-align: right;\">  4.1</td><td style=\"text-align: right;\">      5816</td><td style=\"text-align: right;\">         3.6</td><td>Harry Potter and the Chamber of Secrets (2002)               </td><td>Adventure|Fantasy              </td></tr>\\n<tr><td style=\"text-align: right;\">  4.1</td><td style=\"text-align: right;\">      5952</td><td style=\"text-align: right;\">         4  </td><td>Lord of the Rings: The Two Towers, The (2002)                </td><td>Adventure|Fantasy              </td></tr>\\n<tr><td style=\"text-align: right;\">  4.1</td><td style=\"text-align: right;\">    106489</td><td style=\"text-align: right;\">         3.6</td><td>Hobbit: The Desolation of Smaug, The (2013)                  </td><td>Adventure|Fantasy              </td></tr>\\n</tbody>\\n</table>'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate and replicate the user vector to match the number movies in the data set.\n",
    "user_vecs = gen_user_vecs(user_vec,len(item_vecs))\n",
    "\n",
    "# scale our user and item vectors\n",
    "suser_vecs = scalerUser.transform(user_vecs)\n",
    "sitem_vecs = scalerItem.transform(item_vecs)\n",
    "\n",
    "# make a prediction\n",
    "y_p = model.predict([suser_vecs[:, u_s:], sitem_vecs[:, i_s:]])\n",
    "\n",
    "# unscale y prediction \n",
    "y_pu = scalerTarget.inverse_transform(y_p)\n",
    "\n",
    "# sort the results, highest prediction first\n",
    "sorted_index = np.argsort(-y_pu,axis=0).reshape(-1).tolist()  #negate to get largest rating first\n",
    "'''\n",
    "np.argsort(-y_pu, axis=0):\n",
    "np.argsort(): This is a NumPy function that returns the indices that would sort an array. In other words, it gives you the order of the elements from smallest to largest (by default).\n",
    "-y_pu: This negates the values of y_pu. The reason for negating is to change the sorting order. Normally, np.argsort() will return the indices in ascending order, but by negating y_pu, you ensure that the largest values come first. For example:\n",
    "If y_pu = [3, 1, 5, 4], then -y_pu = [-3, -1, -5, -4], and sorting the negative values will result in the indices [2, 3, 0, 1], which corresponds to the order of largest to smallest values in the original array.\n",
    "axis=0: This indicates that the sorting will be done along the first axis (typically rows). In this case, if y_pu is a 1D array, this is just a simple sort. If y_pu is a 2D array, it will sort each column individually along the rows.\n",
    "So, this step is sorting the values in y_pu in descending order, and the function returns the indices of the sorted elements.\n",
    ".reshape(-1):\n",
    "reshape(-1): This reshapes the array to a 1D vector. The -1 means \"flatten the array,\" regardless of its original shape. It makes sure that the output of np.argsort() is in a 1D form, which is useful for accessing elements sequentially.\n",
    ".tolist():\n",
    ".tolist(): This converts the NumPy array into a standard Python list. This makes the output easier to work with in Python if you need to access or manipulate it using typical Python list operations.\n",
    "What does this code do?\n",
    "The goal of this code is to sort the elements in y_pu in descending order and return the indices of the elements in that order.\n",
    "The sorted indices are then reshaped into a 1D list and returned as a Python list.\n",
    "'''\n",
    "sorted_ypu   = y_pu[sorted_index]\n",
    "sorted_items = item_vecs[sorted_index]  #using unscaled vectors for display\n",
    "\n",
    "print_pred_movies(sorted_ypu, sorted_items, movie_dict, maxcount = 10)\n",
    "type(y_p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(847, 1)\n"
     ]
    }
   ],
   "source": [
    "type(y_p)\n",
    "print(y_p.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a name=\"5.2\"></a>\n",
    "### 5.2 - Predictions for an existing user.\n",
    "Let's look at the predictions for \"user 2\", one of the users in the data set. We can compare the predicted ratings with the model's ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th style=\"text-align: right;\">  y_p</th><th style=\"text-align: right;\">  y</th><th style=\"text-align: right;\">  user</th><th>user genre ave           </th><th style=\"text-align: right;\">  movie rating ave</th><th style=\"text-align: right;\">  movie id</th><th>title                                             </th><th>genres                                    </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: right;\">  4.5</td><td style=\"text-align: right;\">5.0</td><td style=\"text-align: right;\">     2</td><td>[4.0]                    </td><td style=\"text-align: right;\">               4.3</td><td style=\"text-align: right;\">     80906</td><td>Inside Job (2010)                                 </td><td>Documentary                               </td></tr>\n",
       "<tr><td style=\"text-align: right;\">  4.2</td><td style=\"text-align: right;\">4.0</td><td style=\"text-align: right;\">     2</td><td>[4.0,4.1,4.0,4.0,3.9,3.9]</td><td style=\"text-align: right;\">               4.1</td><td style=\"text-align: right;\">     79132</td><td>Inception (2010)                                  </td><td>Action|Crime|Drama|Mystery|Sci-Fi|Thriller</td></tr>\n",
       "<tr><td style=\"text-align: right;\">  4.2</td><td style=\"text-align: right;\">5.0</td><td style=\"text-align: right;\">     2</td><td>[4.0,4.1,4.0]            </td><td style=\"text-align: right;\">               3.9</td><td style=\"text-align: right;\">    106782</td><td>Wolf of Wall Street, The (2013)                   </td><td>Comedy|Crime|Drama                        </td></tr>\n",
       "<tr><td style=\"text-align: right;\">  4.1</td><td style=\"text-align: right;\">4.5</td><td style=\"text-align: right;\">     2</td><td>[4.0,4.1,4.0]            </td><td style=\"text-align: right;\">               4.2</td><td style=\"text-align: right;\">     58559</td><td>Dark Knight, The (2008)                           </td><td>Action|Crime|Drama                        </td></tr>\n",
       "<tr><td style=\"text-align: right;\">  4.1</td><td style=\"text-align: right;\">3.0</td><td style=\"text-align: right;\">     2</td><td>[3.9]                    </td><td style=\"text-align: right;\">               4.0</td><td style=\"text-align: right;\">    109487</td><td>Interstellar (2014)                               </td><td>Sci-Fi                                    </td></tr>\n",
       "<tr><td style=\"text-align: right;\">  4.1</td><td style=\"text-align: right;\">4.0</td><td style=\"text-align: right;\">     2</td><td>[4.1,4.0,3.9]            </td><td style=\"text-align: right;\">               4.3</td><td style=\"text-align: right;\">     48516</td><td>Departed, The (2006)                              </td><td>Crime|Drama|Thriller                      </td></tr>\n",
       "<tr><td style=\"text-align: right;\">  4.1</td><td style=\"text-align: right;\">4.0</td><td style=\"text-align: right;\">     2</td><td>[4.0,4.1,3.9]            </td><td style=\"text-align: right;\">               4.0</td><td style=\"text-align: right;\">      6874</td><td>Kill Bill: Vol. 1 (2003)                          </td><td>Action|Crime|Thriller                     </td></tr>\n",
       "<tr><td style=\"text-align: right;\">  4.0</td><td style=\"text-align: right;\">4.5</td><td style=\"text-align: right;\">     2</td><td>[4.0,4.0]                </td><td style=\"text-align: right;\">               4.1</td><td style=\"text-align: right;\">     68157</td><td>Inglourious Basterds (2009)                       </td><td>Action|Drama                              </td></tr>\n",
       "<tr><td style=\"text-align: right;\">  4.0</td><td style=\"text-align: right;\">3.5</td><td style=\"text-align: right;\">     2</td><td>[4.0,3.9,3.9]            </td><td style=\"text-align: right;\">               3.9</td><td style=\"text-align: right;\">    115713</td><td>Ex Machina (2015)                                 </td><td>Drama|Sci-Fi|Thriller                     </td></tr>\n",
       "<tr><td style=\"text-align: right;\">  4.0</td><td style=\"text-align: right;\">3.5</td><td style=\"text-align: right;\">     2</td><td>[4.0,4.0]                </td><td style=\"text-align: right;\">               3.9</td><td style=\"text-align: right;\">     99114</td><td>Django Unchained (2012)                           </td><td>Action|Drama                              </td></tr>\n",
       "<tr><td style=\"text-align: right;\">  4.0</td><td style=\"text-align: right;\">3.5</td><td style=\"text-align: right;\">     2</td><td>[4.0,4.1,4.0,3.9]        </td><td style=\"text-align: right;\">               3.8</td><td style=\"text-align: right;\">      8798</td><td>Collateral (2004)                                 </td><td>Action|Crime|Drama|Thriller               </td></tr>\n",
       "<tr><td style=\"text-align: right;\">  3.9</td><td style=\"text-align: right;\">3.5</td><td style=\"text-align: right;\">     2</td><td>[4.0,4.2,4.1]            </td><td style=\"text-align: right;\">               4.0</td><td style=\"text-align: right;\">     91529</td><td>Dark Knight Rises, The (2012)                     </td><td>Action|Adventure|Crime                    </td></tr>\n",
       "<tr><td style=\"text-align: right;\">  3.8</td><td style=\"text-align: right;\">5.0</td><td style=\"text-align: right;\">     2</td><td>[4.0]                    </td><td style=\"text-align: right;\">               3.7</td><td style=\"text-align: right;\">     89774</td><td>Warrior (2011)                                    </td><td>Drama                                     </td></tr>\n",
       "<tr><td style=\"text-align: right;\">  3.8</td><td style=\"text-align: right;\">4.5</td><td style=\"text-align: right;\">     2</td><td>[4.1,4.0,3.9]            </td><td style=\"text-align: right;\">               4.0</td><td style=\"text-align: right;\">     80489</td><td>Town, The (2010)                                  </td><td>Crime|Drama|Thriller                      </td></tr>\n",
       "<tr><td style=\"text-align: right;\">  3.8</td><td style=\"text-align: right;\">4.0</td><td style=\"text-align: right;\">     2</td><td>[4.0]                    </td><td style=\"text-align: right;\">               4.0</td><td style=\"text-align: right;\">    112552</td><td>Whiplash (2014)                                   </td><td>Drama                                     </td></tr>\n",
       "<tr><td style=\"text-align: right;\">  3.8</td><td style=\"text-align: right;\">5.0</td><td style=\"text-align: right;\">     2</td><td>[4.0,4.2,3.9,3.9]        </td><td style=\"text-align: right;\">               3.8</td><td style=\"text-align: right;\">    122882</td><td>Mad Max: Fury Road (2015)                         </td><td>Action|Adventure|Sci-Fi|Thriller          </td></tr>\n",
       "<tr><td style=\"text-align: right;\">  3.7</td><td style=\"text-align: right;\">4.0</td><td style=\"text-align: right;\">     2</td><td>[4.0,4.0,3.9]            </td><td style=\"text-align: right;\">               4.0</td><td style=\"text-align: right;\">     74458</td><td>Shutter Island (2010)                             </td><td>Drama|Mystery|Thriller                    </td></tr>\n",
       "<tr><td style=\"text-align: right;\">  3.6</td><td style=\"text-align: right;\">2.5</td><td style=\"text-align: right;\">     2</td><td>[4.0,3.9]                </td><td style=\"text-align: right;\">               3.5</td><td style=\"text-align: right;\">     91658</td><td>Girl with the Dragon Tattoo, The (2011)           </td><td>Drama|Thriller                            </td></tr>\n",
       "<tr><td style=\"text-align: right;\">  3.5</td><td style=\"text-align: right;\">5.0</td><td style=\"text-align: right;\">     2</td><td>[4.0]                    </td><td style=\"text-align: right;\">               3.6</td><td style=\"text-align: right;\">     60756</td><td>Step Brothers (2008)                              </td><td>Comedy                                    </td></tr>\n",
       "<tr><td style=\"text-align: right;\">  3.5</td><td style=\"text-align: right;\">3.0</td><td style=\"text-align: right;\">     2</td><td>[4.0,4.0,3.0]            </td><td style=\"text-align: right;\">               3.9</td><td style=\"text-align: right;\">     71535</td><td>Zombieland (2009)                                 </td><td>Action|Comedy|Horror                      </td></tr>\n",
       "<tr><td style=\"text-align: right;\">  3.2</td><td style=\"text-align: right;\">3.0</td><td style=\"text-align: right;\">     2</td><td>[4.0,4.0]                </td><td style=\"text-align: right;\">               4.0</td><td style=\"text-align: right;\">     77455</td><td>Exit Through the Gift Shop (2010)                 </td><td>Comedy|Documentary                        </td></tr>\n",
       "<tr><td style=\"text-align: right;\">  2.7</td><td style=\"text-align: right;\">4.0</td><td style=\"text-align: right;\">     2</td><td>[4.0,4.0]                </td><td style=\"text-align: right;\">               3.2</td><td style=\"text-align: right;\">     46970</td><td>Talladega Nights: The Ballad of Ricky Bobby (2006)</td><td>Action|Comedy                             </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "'<table>\\n<thead>\\n<tr><th style=\"text-align: right;\">  y_p</th><th style=\"text-align: right;\">  y</th><th style=\"text-align: right;\">  user</th><th>user genre ave           </th><th style=\"text-align: right;\">  movie rating ave</th><th style=\"text-align: right;\">  movie id</th><th>title                                             </th><th>genres                                    </th></tr>\\n</thead>\\n<tbody>\\n<tr><td style=\"text-align: right;\">  4.5</td><td style=\"text-align: right;\">5.0</td><td style=\"text-align: right;\">     2</td><td>[4.0]                    </td><td style=\"text-align: right;\">               4.3</td><td style=\"text-align: right;\">     80906</td><td>Inside Job (2010)                                 </td><td>Documentary                               </td></tr>\\n<tr><td style=\"text-align: right;\">  4.2</td><td style=\"text-align: right;\">4.0</td><td style=\"text-align: right;\">     2</td><td>[4.0,4.1,4.0,4.0,3.9,3.9]</td><td style=\"text-align: right;\">               4.1</td><td style=\"text-align: right;\">     79132</td><td>Inception (2010)                                  </td><td>Action|Crime|Drama|Mystery|Sci-Fi|Thriller</td></tr>\\n<tr><td style=\"text-align: right;\">  4.2</td><td style=\"text-align: right;\">5.0</td><td style=\"text-align: right;\">     2</td><td>[4.0,4.1,4.0]            </td><td style=\"text-align: right;\">               3.9</td><td style=\"text-align: right;\">    106782</td><td>Wolf of Wall Street, The (2013)                   </td><td>Comedy|Crime|Drama                        </td></tr>\\n<tr><td style=\"text-align: right;\">  4.1</td><td style=\"text-align: right;\">4.5</td><td style=\"text-align: right;\">     2</td><td>[4.0,4.1,4.0]            </td><td style=\"text-align: right;\">               4.2</td><td style=\"text-align: right;\">     58559</td><td>Dark Knight, The (2008)                           </td><td>Action|Crime|Drama                        </td></tr>\\n<tr><td style=\"text-align: right;\">  4.1</td><td style=\"text-align: right;\">3.0</td><td style=\"text-align: right;\">     2</td><td>[3.9]                    </td><td style=\"text-align: right;\">               4.0</td><td style=\"text-align: right;\">    109487</td><td>Interstellar (2014)                               </td><td>Sci-Fi                                    </td></tr>\\n<tr><td style=\"text-align: right;\">  4.1</td><td style=\"text-align: right;\">4.0</td><td style=\"text-align: right;\">     2</td><td>[4.1,4.0,3.9]            </td><td style=\"text-align: right;\">               4.3</td><td style=\"text-align: right;\">     48516</td><td>Departed, The (2006)                              </td><td>Crime|Drama|Thriller                      </td></tr>\\n<tr><td style=\"text-align: right;\">  4.1</td><td style=\"text-align: right;\">4.0</td><td style=\"text-align: right;\">     2</td><td>[4.0,4.1,3.9]            </td><td style=\"text-align: right;\">               4.0</td><td style=\"text-align: right;\">      6874</td><td>Kill Bill: Vol. 1 (2003)                          </td><td>Action|Crime|Thriller                     </td></tr>\\n<tr><td style=\"text-align: right;\">  4.0</td><td style=\"text-align: right;\">4.5</td><td style=\"text-align: right;\">     2</td><td>[4.0,4.0]                </td><td style=\"text-align: right;\">               4.1</td><td style=\"text-align: right;\">     68157</td><td>Inglourious Basterds (2009)                       </td><td>Action|Drama                              </td></tr>\\n<tr><td style=\"text-align: right;\">  4.0</td><td style=\"text-align: right;\">3.5</td><td style=\"text-align: right;\">     2</td><td>[4.0,3.9,3.9]            </td><td style=\"text-align: right;\">               3.9</td><td style=\"text-align: right;\">    115713</td><td>Ex Machina (2015)                                 </td><td>Drama|Sci-Fi|Thriller                     </td></tr>\\n<tr><td style=\"text-align: right;\">  4.0</td><td style=\"text-align: right;\">3.5</td><td style=\"text-align: right;\">     2</td><td>[4.0,4.0]                </td><td style=\"text-align: right;\">               3.9</td><td style=\"text-align: right;\">     99114</td><td>Django Unchained (2012)                           </td><td>Action|Drama                              </td></tr>\\n<tr><td style=\"text-align: right;\">  4.0</td><td style=\"text-align: right;\">3.5</td><td style=\"text-align: right;\">     2</td><td>[4.0,4.1,4.0,3.9]        </td><td style=\"text-align: right;\">               3.8</td><td style=\"text-align: right;\">      8798</td><td>Collateral (2004)                                 </td><td>Action|Crime|Drama|Thriller               </td></tr>\\n<tr><td style=\"text-align: right;\">  3.9</td><td style=\"text-align: right;\">3.5</td><td style=\"text-align: right;\">     2</td><td>[4.0,4.2,4.1]            </td><td style=\"text-align: right;\">               4.0</td><td style=\"text-align: right;\">     91529</td><td>Dark Knight Rises, The (2012)                     </td><td>Action|Adventure|Crime                    </td></tr>\\n<tr><td style=\"text-align: right;\">  3.8</td><td style=\"text-align: right;\">5.0</td><td style=\"text-align: right;\">     2</td><td>[4.0]                    </td><td style=\"text-align: right;\">               3.7</td><td style=\"text-align: right;\">     89774</td><td>Warrior (2011)                                    </td><td>Drama                                     </td></tr>\\n<tr><td style=\"text-align: right;\">  3.8</td><td style=\"text-align: right;\">4.5</td><td style=\"text-align: right;\">     2</td><td>[4.1,4.0,3.9]            </td><td style=\"text-align: right;\">               4.0</td><td style=\"text-align: right;\">     80489</td><td>Town, The (2010)                                  </td><td>Crime|Drama|Thriller                      </td></tr>\\n<tr><td style=\"text-align: right;\">  3.8</td><td style=\"text-align: right;\">4.0</td><td style=\"text-align: right;\">     2</td><td>[4.0]                    </td><td style=\"text-align: right;\">               4.0</td><td style=\"text-align: right;\">    112552</td><td>Whiplash (2014)                                   </td><td>Drama                                     </td></tr>\\n<tr><td style=\"text-align: right;\">  3.8</td><td style=\"text-align: right;\">5.0</td><td style=\"text-align: right;\">     2</td><td>[4.0,4.2,3.9,3.9]        </td><td style=\"text-align: right;\">               3.8</td><td style=\"text-align: right;\">    122882</td><td>Mad Max: Fury Road (2015)                         </td><td>Action|Adventure|Sci-Fi|Thriller          </td></tr>\\n<tr><td style=\"text-align: right;\">  3.7</td><td style=\"text-align: right;\">4.0</td><td style=\"text-align: right;\">     2</td><td>[4.0,4.0,3.9]            </td><td style=\"text-align: right;\">               4.0</td><td style=\"text-align: right;\">     74458</td><td>Shutter Island (2010)                             </td><td>Drama|Mystery|Thriller                    </td></tr>\\n<tr><td style=\"text-align: right;\">  3.6</td><td style=\"text-align: right;\">2.5</td><td style=\"text-align: right;\">     2</td><td>[4.0,3.9]                </td><td style=\"text-align: right;\">               3.5</td><td style=\"text-align: right;\">     91658</td><td>Girl with the Dragon Tattoo, The (2011)           </td><td>Drama|Thriller                            </td></tr>\\n<tr><td style=\"text-align: right;\">  3.5</td><td style=\"text-align: right;\">5.0</td><td style=\"text-align: right;\">     2</td><td>[4.0]                    </td><td style=\"text-align: right;\">               3.6</td><td style=\"text-align: right;\">     60756</td><td>Step Brothers (2008)                              </td><td>Comedy                                    </td></tr>\\n<tr><td style=\"text-align: right;\">  3.5</td><td style=\"text-align: right;\">3.0</td><td style=\"text-align: right;\">     2</td><td>[4.0,4.0,3.0]            </td><td style=\"text-align: right;\">               3.9</td><td style=\"text-align: right;\">     71535</td><td>Zombieland (2009)                                 </td><td>Action|Comedy|Horror                      </td></tr>\\n<tr><td style=\"text-align: right;\">  3.2</td><td style=\"text-align: right;\">3.0</td><td style=\"text-align: right;\">     2</td><td>[4.0,4.0]                </td><td style=\"text-align: right;\">               4.0</td><td style=\"text-align: right;\">     77455</td><td>Exit Through the Gift Shop (2010)                 </td><td>Comedy|Documentary                        </td></tr>\\n<tr><td style=\"text-align: right;\">  2.7</td><td style=\"text-align: right;\">4.0</td><td style=\"text-align: right;\">     2</td><td>[4.0,4.0]                </td><td style=\"text-align: right;\">               3.2</td><td style=\"text-align: right;\">     46970</td><td>Talladega Nights: The Ballad of Ricky Bobby (2006)</td><td>Action|Comedy                             </td></tr>\\n</tbody>\\n</table>'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uid = 2 \n",
    "# form a set of user vectors. This is the same vector, transformed and repeated.\n",
    "user_vecs, y_vecs = get_user_vecs(uid, user_train_unscaled, item_vecs, user_to_genre)\n",
    "\n",
    "# scale our user and item vectors\n",
    "suser_vecs = scalerUser.transform(user_vecs)\n",
    "sitem_vecs = scalerItem.transform(item_vecs)\n",
    "\n",
    "# make a prediction\n",
    "y_p = model.predict([suser_vecs[:, u_s:], sitem_vecs[:, i_s:]])\n",
    "\n",
    "# unscale y prediction \n",
    "y_pu = scalerTarget.inverse_transform(y_p)\n",
    "\n",
    "# sort the results, highest prediction first\n",
    "sorted_index = np.argsort(-y_pu,axis=0).reshape(-1).tolist()  #negate to get largest rating first\n",
    "sorted_ypu   = y_pu[sorted_index]\n",
    "sorted_items = item_vecs[sorted_index]  #using unscaled vectors for display\n",
    "sorted_user  = user_vecs[sorted_index]\n",
    "sorted_y     = y_vecs[sorted_index]\n",
    "\n",
    "#print sorted predictions for movies rated by the user\n",
    "print_existing_user(sorted_ypu, sorted_y.reshape(-1,1), sorted_user, sorted_items, ivs, uvs, movie_dict, maxcount = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22,)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_y[sorted_y !=0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model prediction is generally within 1 of the actual rating though it is not a very accurate predictor of how a user rates specific movies. This is especially true if the user rating is significantly different than the user's genre average. You can vary the user id above to try different users. Not all user id's were used in the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"5.3\"></a>\n",
    "### 5.3 - Finding Similar Items\n",
    "The neural network above produces two feature vectors, a user feature vector $v_u$, and a movie feature vector, $v_m$. These are 32 entry vectors whose values are difficult to interpret. However, similar items will have similar vectors. This information can be used to make recommendations. For example, if a user has rated \"Toy Story 3\" highly, one could recommend similar movies by selecting movies with similar movie feature vectors.\n",
    "\n",
    "A similarity measure is the squared distance between the two vectors $ \\mathbf{v_m^{(k)}}$ and $\\mathbf{v_m^{(i)}}$ :\n",
    "$$\\left\\Vert \\mathbf{v_m^{(k)}} - \\mathbf{v_m^{(i)}}  \\right\\Vert^2 = \\sum_{l=1}^{n}(v_{m_l}^{(k)} - v_{m_l}^{(i)})^2\\tag{1}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"ex02\"></a>\n",
    "### Exercise 2\n",
    "\n",
    "Write a function to compute the square distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# GRADED_FUNCTION: sq_dist\n",
    "# UNQ_C2\n",
    "def sq_dist(a,b):\n",
    "    \"\"\"\n",
    "    Returns the squared distance between two vectors\n",
    "    Args:\n",
    "      a (ndarray (n,)): vector with n features\n",
    "      b (ndarray (n,)): vector with n features\n",
    "    Returns:\n",
    "      d (float) : distance\n",
    "    \"\"\"\n",
    "    ### START CODE HERE ###     \n",
    "    d = np.sum((a-b)**2)\n",
    "    ### END CODE HERE ###     \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(6.0)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(a1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "squared distance between a1 and b1: 0.000\n",
      "squared distance between a2 and b2: 0.030\n",
      "squared distance between a3 and b3: 2.000\n"
     ]
    }
   ],
   "source": [
    "a1 = np.array([1.0, 2.0, 3.0]); b1 = np.array([1.0, 2.0, 3.0])\n",
    "a2 = np.array([1.1, 2.1, 3.1]); b2 = np.array([1.0, 2.0, 3.0])\n",
    "a3 = np.array([0, 1, 0]);       b3 = np.array([1, 0, 0])\n",
    "print(f\"squared distance between a1 and b1: {sq_dist(a1, b1):0.3f}\")\n",
    "print(f\"squared distance between a2 and b2: {sq_dist(a2, b2):0.3f}\")\n",
    "print(f\"squared distance between a3 and b3: {sq_dist(a3, b3):0.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**:\n",
    "\n",
    "squared distance between a1 and b1: 0.000    \n",
    "squared distance between a2 and b2: 0.030   \n",
    "squared distance between a3 and b3: 2.000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mAll tests passed!\n"
     ]
    }
   ],
   "source": [
    "# Public tests\n",
    "test_sq_dist(sq_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary><font size=\"3\" color=\"darkgreen\"><b>Click for hints</b></font></summary>\n",
    "    \n",
    "  While a summation is often an indication a for loop should be used, here the subtraction can be element-wise in one statement. Further, you can utilized np.square to square, element-wise, the result of the subtraction. np.sum can be used to sum the squared elements.\n",
    "    \n",
    "</details>\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A matrix of distances between movies can be computed once when the model is trained and then reused for new recommendations without retraining. The first step, once a model is trained, is to obtain the movie feature vector, $v_m$, for each of the movies. To do this, we will use the trained `item_NN` and build a small model to allow us to run the movie vectors through it to generate $v_m$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the item input and point to the base network\n",
    "input_item = tf.keras.layers.Input(shape=(num_item_features,))\n",
    "# vm = item_NN(input_item)\n",
    "# vm = tf.linalg.l2_normalize(vm, axis=1)\n",
    "# Create user input layer\n",
    "vm = item_NN(input_item)\n",
    "\n",
    "# Normalize the output using L2 Normalization (using Lambda layer)\n",
    "vm = Lambda(lambda x: tf.nn.l2_normalize(x, axis=1))(vm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ input_layer_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ sequential_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">41,376</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ lambda_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ input_layer_5 (\u001b[38;5;33mInputLayer\u001b[0m)      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ sequential_1 (\u001b[38;5;33mSequential\u001b[0m)       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             â”‚        \u001b[38;5;34m41,376\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ lambda_2 (\u001b[38;5;33mLambda\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">41,376</span> (161.62 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m41,376\u001b[0m (161.62 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">41,376</span> (161.62 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m41,376\u001b[0m (161.62 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_item_m = tf.keras.layers.Input(shape=(num_item_features,))    # input layer\n",
    "vm_m = item_NN(input_item_m)                                       # use the trained item_NN\n",
    "vm_m = Lambda(lambda x: tf.nn.l2_normalize(x, axis=1))(vm_m)       # incorporate normalization as was done in the original model\n",
    "\n",
    "# specify the inputs and output of the model\n",
    "model_m = tf.keras.Model(input_item_m, vm_m)                                \n",
    "model_m.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have a movie model, you can create a set of movie feature vectors by using the model to predict using a set of item/movie vectors as input. `item_vecs` is a set of all of the movie vectors. It must be scaled to use with the trained model. The result of the prediction is a 32 entry feature vector for each movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(847, 17)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_vecs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "size of all predicted movie feature vectors: (847, 32)\n"
     ]
    }
   ],
   "source": [
    "scaled_item_vecs = scalerItem.transform(item_vecs)\n",
    "vms = model_m.predict(scaled_item_vecs[:,i_s:])\n",
    "print(f\"size of all predicted movie feature vectors: {vms.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now compute a matrix of the squared distance between each movie feature vector and all other movie feature vectors:\n",
    "<figure>\n",
    "    <left> <img src=\"./images/distmatrix.PNG\"   style=\"width:400px;height:225px;\" ></center>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then find the closest movie by finding the minimum along each row. We will make use of [numpy masked arrays](https://numpy.org/doc/1.21/user/tutorial-ma.html) to avoid selecting the same movie. The masked values along the diagonal won't be included in the computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>movie1                                  </th><th>genres                                             </th><th>movie2                                                                     </th><th>genres                                             </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>Save the Last Dance (2001)              </td><td>Drama|Romance                                      </td><td>Mona Lisa Smile (2003)                                                     </td><td>Drama|Romance                                      </td></tr>\n",
       "<tr><td>Wedding Planner, The (2001)             </td><td>Comedy|Romance                                     </td><td>Mr. Deeds (2002)                                                           </td><td>Comedy|Romance                                     </td></tr>\n",
       "<tr><td>Hannibal (2001)                         </td><td>Horror|Thriller                                    </td><td>Final Destination 2 (2003)                                                 </td><td>Horror|Thriller                                    </td></tr>\n",
       "<tr><td>Saving Silverman (Evil Woman) (2001)    </td><td>Comedy|Romance                                     </td><td>Sweetest Thing, The (2002)                                                 </td><td>Comedy|Romance                                     </td></tr>\n",
       "<tr><td>Down to Earth (2001)                    </td><td>Comedy|Fantasy|Romance                             </td><td>America&#x27;s Sweethearts (2001)                                               </td><td>Comedy|Fantasy|Romance                             </td></tr>\n",
       "<tr><td>Mexican, The (2001)                     </td><td>Action|Comedy                                      </td><td>Rush Hour 2 (2001)                                                         </td><td>Action|Comedy                                      </td></tr>\n",
       "<tr><td>15 Minutes (2001)                       </td><td>Thriller                                           </td><td>Panic Room (2002)                                                          </td><td>Thriller                                           </td></tr>\n",
       "<tr><td>Enemy at the Gates (2001)               </td><td>Drama                                              </td><td>Aviator, The (2004)                                                        </td><td>Drama                                              </td></tr>\n",
       "<tr><td>Heartbreakers (2001)                    </td><td>Comedy|Crime|Romance                               </td><td>Fast and the Furious: Tokyo Drift, The (Fast and the Furious 3, The) (2006)</td><td>Comedy|Crime|Romance                               </td></tr>\n",
       "<tr><td>Spy Kids (2001)                         </td><td>Action|Adventure|Children|Comedy                   </td><td>Scooby-Doo (2002)                                                          </td><td>Action|Adventure|Children|Comedy                   </td></tr>\n",
       "<tr><td>Along Came a Spider (2001)              </td><td>Action|Crime|Mystery|Thriller                      </td><td>Silent Hill (2006)                                                         </td><td>Action|Crime|Mystery|Thriller                      </td></tr>\n",
       "<tr><td>Blow (2001)                             </td><td>Crime|Drama                                        </td><td>25th Hour (2002)                                                           </td><td>Crime|Drama                                        </td></tr>\n",
       "<tr><td>Bridget Jones&#x27;s Diary (2001)            </td><td>Comedy|Drama|Romance                               </td><td>Punch-Drunk Love (2002)                                                    </td><td>Comedy|Drama|Romance                               </td></tr>\n",
       "<tr><td>Joe Dirt (2001)                         </td><td>Adventure|Comedy|Mystery|Romance                   </td><td>Elektra (2005)                                                             </td><td>Adventure|Comedy|Mystery|Romance                   </td></tr>\n",
       "<tr><td>Crocodile Dundee in Los Angeles (2001)  </td><td>Comedy|Drama                                       </td><td>Animal, The (2001)                                                         </td><td>Comedy|Drama                                       </td></tr>\n",
       "<tr><td>Mummy Returns, The (2001)               </td><td>Action|Adventure|Comedy|Thriller                   </td><td>Scooby-Doo (2002)                                                          </td><td>Action|Adventure|Comedy|Thriller                   </td></tr>\n",
       "<tr><td>Knight&#x27;s Tale, A (2001)                 </td><td>Action|Comedy|Romance                              </td><td>Shallow Hal (2001)                                                         </td><td>Action|Comedy|Romance                              </td></tr>\n",
       "<tr><td>Shrek (2001)                            </td><td>Adventure|Animation|Children|Comedy|Fantasy|Romance</td><td>Enchanted (2007)                                                           </td><td>Adventure|Animation|Children|Comedy|Fantasy|Romance</td></tr>\n",
       "<tr><td>Moulin Rouge (2001)                     </td><td>Drama|Romance                                      </td><td>Hours, The (2002)                                                          </td><td>Drama|Romance                                      </td></tr>\n",
       "<tr><td>Pearl Harbor (2001)                     </td><td>Action|Drama|Romance                               </td><td>Click (2006)                                                               </td><td>Action|Drama|Romance                               </td></tr>\n",
       "<tr><td>Animal, The (2001)                      </td><td>Comedy                                             </td><td>Dumb and Dumberer: When Harry Met Lloyd (2003)                             </td><td>Comedy                                             </td></tr>\n",
       "<tr><td>Evolution (2001)                        </td><td>Comedy|Sci-Fi                                      </td><td>Austin Powers in Goldmember (2002)                                         </td><td>Comedy|Sci-Fi                                      </td></tr>\n",
       "<tr><td>Swordfish (2001)                        </td><td>Action|Crime|Drama                                 </td><td>Behind Enemy Lines (2001)                                                  </td><td>Action|Crime|Drama                                 </td></tr>\n",
       "<tr><td>Atlantis: The Lost Empire (2001)        </td><td>Adventure|Animation|Children|Fantasy               </td><td>Spy Kids (2001)                                                            </td><td>Adventure|Animation|Children|Fantasy               </td></tr>\n",
       "<tr><td>Lara Croft: Tomb Raider (2001)          </td><td>Action|Adventure                                   </td><td>National Treasure: Book of Secrets (2007)                                  </td><td>Action|Adventure                                   </td></tr>\n",
       "<tr><td>Dr. Dolittle 2 (2001)                   </td><td>Comedy                                             </td><td>Legally Blonde 2: Red, White &amp; Blonde (2003)                               </td><td>Comedy                                             </td></tr>\n",
       "<tr><td>Fast and the Furious, The (2001)        </td><td>Action|Crime|Thriller                              </td><td>Once Upon a Time in Mexico (2003)                                          </td><td>Action|Crime|Thriller                              </td></tr>\n",
       "<tr><td>A.I. Artificial Intelligence (2001)     </td><td>Adventure|Drama|Sci-Fi                             </td><td>Enemy at the Gates (2001)                                                  </td><td>Adventure|Drama|Sci-Fi                             </td></tr>\n",
       "<tr><td>Cats &amp; Dogs (2001)                      </td><td>Children|Comedy                                    </td><td>Shark Tale (2004)                                                          </td><td>Children|Comedy                                    </td></tr>\n",
       "<tr><td>Scary Movie 2 (2001)                    </td><td>Comedy                                             </td><td>Orange County (2002)                                                       </td><td>Comedy                                             </td></tr>\n",
       "<tr><td>Final Fantasy: The Spirits Within (2001)</td><td>Adventure|Animation|Fantasy|Sci-Fi                 </td><td>Pineapple Express (2008)                                                   </td><td>Adventure|Animation|Fantasy|Sci-Fi                 </td></tr>\n",
       "<tr><td>Legally Blonde (2001)                   </td><td>Comedy|Romance                                     </td><td>Serendipity (2001)                                                         </td><td>Comedy|Romance                                     </td></tr>\n",
       "<tr><td>Score, The (2001)                       </td><td>Action|Drama                                       </td><td>Jarhead (2005)                                                             </td><td>Action|Drama                                       </td></tr>\n",
       "<tr><td>Jurassic Park III (2001)                </td><td>Action|Adventure|Sci-Fi|Thriller                   </td><td>Paycheck (2003)                                                            </td><td>Action|Adventure|Sci-Fi|Thriller                   </td></tr>\n",
       "<tr><td>America&#x27;s Sweethearts (2001)            </td><td>Comedy|Romance                                     </td><td>Maid in Manhattan (2002)                                                   </td><td>Comedy|Romance                                     </td></tr>\n",
       "<tr><td>Ghost World (2001)                      </td><td>Comedy|Drama                                       </td><td>Station Agent, The (2003)                                                  </td><td>Comedy|Drama                                       </td></tr>\n",
       "<tr><td>Planet of the Apes (2001)               </td><td>Action|Adventure|Drama|Sci-Fi                      </td><td>Day After Tomorrow, The (2004)                                             </td><td>Action|Adventure|Drama|Sci-Fi                      </td></tr>\n",
       "<tr><td>Princess Diaries, The (2001)            </td><td>Children|Comedy|Romance                            </td><td>Freaky Friday (2003)                                                       </td><td>Children|Comedy|Romance                            </td></tr>\n",
       "<tr><td>Rush Hour 2 (2001)                      </td><td>Action|Comedy                                      </td><td>Mexican, The (2001)                                                        </td><td>Action|Comedy                                      </td></tr>\n",
       "<tr><td>American Pie 2 (2001)                   </td><td>Comedy                                             </td><td>Rat Race (2001)                                                            </td><td>Comedy                                             </td></tr>\n",
       "<tr><td>Others, The (2001)                      </td><td>Drama|Horror|Mystery|Thriller                      </td><td>Dogville (2003)                                                            </td><td>Drama|Horror|Mystery|Thriller                      </td></tr>\n",
       "<tr><td>Rat Race (2001)                         </td><td>Comedy                                             </td><td>American Pie 2 (2001)                                                      </td><td>Comedy                                             </td></tr>\n",
       "<tr><td>Jay and Silent Bob Strike Back (2001)   </td><td>Adventure|Comedy                                   </td><td>EuroTrip (2004)                                                            </td><td>Adventure|Comedy                                   </td></tr>\n",
       "<tr><td>Training Day (2001)                     </td><td>Crime|Drama|Thriller                               </td><td>Frailty (2001)                                                             </td><td>Crime|Drama|Thriller                               </td></tr>\n",
       "<tr><td>Zoolander (2001)                        </td><td>Comedy                                             </td><td>Old School (2003)                                                          </td><td>Comedy                                             </td></tr>\n",
       "<tr><td>Serendipity (2001)                      </td><td>Comedy|Romance                                     </td><td>Legally Blonde (2001)                                                      </td><td>Comedy|Romance                                     </td></tr>\n",
       "<tr><td>Mulholland Drive (2001)                 </td><td>Crime|Drama|Mystery|Thriller                       </td><td>Old Boy (2003)                                                             </td><td>Crime|Drama|Mystery|Thriller                       </td></tr>\n",
       "<tr><td>From Hell (2001)                        </td><td>Crime|Horror|Mystery|Thriller                      </td><td>Identity (2003)                                                            </td><td>Crime|Horror|Mystery|Thriller                      </td></tr>\n",
       "<tr><td>Waking Life (2001)                      </td><td>Animation|Drama|Fantasy                            </td><td>Corpse Bride (2005)                                                        </td><td>Animation|Drama|Fantasy                            </td></tr>\n",
       "<tr><td>K-PAX (2001)                            </td><td>Drama|Fantasy|Mystery|Sci-Fi                       </td><td>Gosford Park (2001)                                                        </td><td>Drama|Fantasy|Mystery|Sci-Fi                       </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "'<table>\\n<thead>\\n<tr><th>movie1                                  </th><th>genres                                             </th><th>movie2                                                                     </th><th>genres                                             </th></tr>\\n</thead>\\n<tbody>\\n<tr><td>Save the Last Dance (2001)              </td><td>Drama|Romance                                      </td><td>Mona Lisa Smile (2003)                                                     </td><td>Drama|Romance                                      </td></tr>\\n<tr><td>Wedding Planner, The (2001)             </td><td>Comedy|Romance                                     </td><td>Mr. Deeds (2002)                                                           </td><td>Comedy|Romance                                     </td></tr>\\n<tr><td>Hannibal (2001)                         </td><td>Horror|Thriller                                    </td><td>Final Destination 2 (2003)                                                 </td><td>Horror|Thriller                                    </td></tr>\\n<tr><td>Saving Silverman (Evil Woman) (2001)    </td><td>Comedy|Romance                                     </td><td>Sweetest Thing, The (2002)                                                 </td><td>Comedy|Romance                                     </td></tr>\\n<tr><td>Down to Earth (2001)                    </td><td>Comedy|Fantasy|Romance                             </td><td>America&#x27;s Sweethearts (2001)                                               </td><td>Comedy|Fantasy|Romance                             </td></tr>\\n<tr><td>Mexican, The (2001)                     </td><td>Action|Comedy                                      </td><td>Rush Hour 2 (2001)                                                         </td><td>Action|Comedy                                      </td></tr>\\n<tr><td>15 Minutes (2001)                       </td><td>Thriller                                           </td><td>Panic Room (2002)                                                          </td><td>Thriller                                           </td></tr>\\n<tr><td>Enemy at the Gates (2001)               </td><td>Drama                                              </td><td>Aviator, The (2004)                                                        </td><td>Drama                                              </td></tr>\\n<tr><td>Heartbreakers (2001)                    </td><td>Comedy|Crime|Romance                               </td><td>Fast and the Furious: Tokyo Drift, The (Fast and the Furious 3, The) (2006)</td><td>Comedy|Crime|Romance                               </td></tr>\\n<tr><td>Spy Kids (2001)                         </td><td>Action|Adventure|Children|Comedy                   </td><td>Scooby-Doo (2002)                                                          </td><td>Action|Adventure|Children|Comedy                   </td></tr>\\n<tr><td>Along Came a Spider (2001)              </td><td>Action|Crime|Mystery|Thriller                      </td><td>Silent Hill (2006)                                                         </td><td>Action|Crime|Mystery|Thriller                      </td></tr>\\n<tr><td>Blow (2001)                             </td><td>Crime|Drama                                        </td><td>25th Hour (2002)                                                           </td><td>Crime|Drama                                        </td></tr>\\n<tr><td>Bridget Jones&#x27;s Diary (2001)            </td><td>Comedy|Drama|Romance                               </td><td>Punch-Drunk Love (2002)                                                    </td><td>Comedy|Drama|Romance                               </td></tr>\\n<tr><td>Joe Dirt (2001)                         </td><td>Adventure|Comedy|Mystery|Romance                   </td><td>Elektra (2005)                                                             </td><td>Adventure|Comedy|Mystery|Romance                   </td></tr>\\n<tr><td>Crocodile Dundee in Los Angeles (2001)  </td><td>Comedy|Drama                                       </td><td>Animal, The (2001)                                                         </td><td>Comedy|Drama                                       </td></tr>\\n<tr><td>Mummy Returns, The (2001)               </td><td>Action|Adventure|Comedy|Thriller                   </td><td>Scooby-Doo (2002)                                                          </td><td>Action|Adventure|Comedy|Thriller                   </td></tr>\\n<tr><td>Knight&#x27;s Tale, A (2001)                 </td><td>Action|Comedy|Romance                              </td><td>Shallow Hal (2001)                                                         </td><td>Action|Comedy|Romance                              </td></tr>\\n<tr><td>Shrek (2001)                            </td><td>Adventure|Animation|Children|Comedy|Fantasy|Romance</td><td>Enchanted (2007)                                                           </td><td>Adventure|Animation|Children|Comedy|Fantasy|Romance</td></tr>\\n<tr><td>Moulin Rouge (2001)                     </td><td>Drama|Romance                                      </td><td>Hours, The (2002)                                                          </td><td>Drama|Romance                                      </td></tr>\\n<tr><td>Pearl Harbor (2001)                     </td><td>Action|Drama|Romance                               </td><td>Click (2006)                                                               </td><td>Action|Drama|Romance                               </td></tr>\\n<tr><td>Animal, The (2001)                      </td><td>Comedy                                             </td><td>Dumb and Dumberer: When Harry Met Lloyd (2003)                             </td><td>Comedy                                             </td></tr>\\n<tr><td>Evolution (2001)                        </td><td>Comedy|Sci-Fi                                      </td><td>Austin Powers in Goldmember (2002)                                         </td><td>Comedy|Sci-Fi                                      </td></tr>\\n<tr><td>Swordfish (2001)                        </td><td>Action|Crime|Drama                                 </td><td>Behind Enemy Lines (2001)                                                  </td><td>Action|Crime|Drama                                 </td></tr>\\n<tr><td>Atlantis: The Lost Empire (2001)        </td><td>Adventure|Animation|Children|Fantasy               </td><td>Spy Kids (2001)                                                            </td><td>Adventure|Animation|Children|Fantasy               </td></tr>\\n<tr><td>Lara Croft: Tomb Raider (2001)          </td><td>Action|Adventure                                   </td><td>National Treasure: Book of Secrets (2007)                                  </td><td>Action|Adventure                                   </td></tr>\\n<tr><td>Dr. Dolittle 2 (2001)                   </td><td>Comedy                                             </td><td>Legally Blonde 2: Red, White &amp; Blonde (2003)                               </td><td>Comedy                                             </td></tr>\\n<tr><td>Fast and the Furious, The (2001)        </td><td>Action|Crime|Thriller                              </td><td>Once Upon a Time in Mexico (2003)                                          </td><td>Action|Crime|Thriller                              </td></tr>\\n<tr><td>A.I. Artificial Intelligence (2001)     </td><td>Adventure|Drama|Sci-Fi                             </td><td>Enemy at the Gates (2001)                                                  </td><td>Adventure|Drama|Sci-Fi                             </td></tr>\\n<tr><td>Cats &amp; Dogs (2001)                      </td><td>Children|Comedy                                    </td><td>Shark Tale (2004)                                                          </td><td>Children|Comedy                                    </td></tr>\\n<tr><td>Scary Movie 2 (2001)                    </td><td>Comedy                                             </td><td>Orange County (2002)                                                       </td><td>Comedy                                             </td></tr>\\n<tr><td>Final Fantasy: The Spirits Within (2001)</td><td>Adventure|Animation|Fantasy|Sci-Fi                 </td><td>Pineapple Express (2008)                                                   </td><td>Adventure|Animation|Fantasy|Sci-Fi                 </td></tr>\\n<tr><td>Legally Blonde (2001)                   </td><td>Comedy|Romance                                     </td><td>Serendipity (2001)                                                         </td><td>Comedy|Romance                                     </td></tr>\\n<tr><td>Score, The (2001)                       </td><td>Action|Drama                                       </td><td>Jarhead (2005)                                                             </td><td>Action|Drama                                       </td></tr>\\n<tr><td>Jurassic Park III (2001)                </td><td>Action|Adventure|Sci-Fi|Thriller                   </td><td>Paycheck (2003)                                                            </td><td>Action|Adventure|Sci-Fi|Thriller                   </td></tr>\\n<tr><td>America&#x27;s Sweethearts (2001)            </td><td>Comedy|Romance                                     </td><td>Maid in Manhattan (2002)                                                   </td><td>Comedy|Romance                                     </td></tr>\\n<tr><td>Ghost World (2001)                      </td><td>Comedy|Drama                                       </td><td>Station Agent, The (2003)                                                  </td><td>Comedy|Drama                                       </td></tr>\\n<tr><td>Planet of the Apes (2001)               </td><td>Action|Adventure|Drama|Sci-Fi                      </td><td>Day After Tomorrow, The (2004)                                             </td><td>Action|Adventure|Drama|Sci-Fi                      </td></tr>\\n<tr><td>Princess Diaries, The (2001)            </td><td>Children|Comedy|Romance                            </td><td>Freaky Friday (2003)                                                       </td><td>Children|Comedy|Romance                            </td></tr>\\n<tr><td>Rush Hour 2 (2001)                      </td><td>Action|Comedy                                      </td><td>Mexican, The (2001)                                                        </td><td>Action|Comedy                                      </td></tr>\\n<tr><td>American Pie 2 (2001)                   </td><td>Comedy                                             </td><td>Rat Race (2001)                                                            </td><td>Comedy                                             </td></tr>\\n<tr><td>Others, The (2001)                      </td><td>Drama|Horror|Mystery|Thriller                      </td><td>Dogville (2003)                                                            </td><td>Drama|Horror|Mystery|Thriller                      </td></tr>\\n<tr><td>Rat Race (2001)                         </td><td>Comedy                                             </td><td>American Pie 2 (2001)                                                      </td><td>Comedy                                             </td></tr>\\n<tr><td>Jay and Silent Bob Strike Back (2001)   </td><td>Adventure|Comedy                                   </td><td>EuroTrip (2004)                                                            </td><td>Adventure|Comedy                                   </td></tr>\\n<tr><td>Training Day (2001)                     </td><td>Crime|Drama|Thriller                               </td><td>Frailty (2001)                                                             </td><td>Crime|Drama|Thriller                               </td></tr>\\n<tr><td>Zoolander (2001)                        </td><td>Comedy                                             </td><td>Old School (2003)                                                          </td><td>Comedy                                             </td></tr>\\n<tr><td>Serendipity (2001)                      </td><td>Comedy|Romance                                     </td><td>Legally Blonde (2001)                                                      </td><td>Comedy|Romance                                     </td></tr>\\n<tr><td>Mulholland Drive (2001)                 </td><td>Crime|Drama|Mystery|Thriller                       </td><td>Old Boy (2003)                                                             </td><td>Crime|Drama|Mystery|Thriller                       </td></tr>\\n<tr><td>From Hell (2001)                        </td><td>Crime|Horror|Mystery|Thriller                      </td><td>Identity (2003)                                                            </td><td>Crime|Horror|Mystery|Thriller                      </td></tr>\\n<tr><td>Waking Life (2001)                      </td><td>Animation|Drama|Fantasy                            </td><td>Corpse Bride (2005)                                                        </td><td>Animation|Drama|Fantasy                            </td></tr>\\n<tr><td>K-PAX (2001)                            </td><td>Drama|Fantasy|Mystery|Sci-Fi                       </td><td>Gosford Park (2001)                                                        </td><td>Drama|Fantasy|Mystery|Sci-Fi                       </td></tr>\\n</tbody>\\n</table>'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The provided code calculates the similarity (using squared distance) between movies and then creates a table to display the most similar movies for a given set of movies.\n",
    "count = 50  # number of movies to display\n",
    "dim = len(vms)  # `dim` is the number of movies you are comparing\n",
    "dist = np.zeros((dim,dim))  # Create a square matrix to hold distances between movies\n",
    "'''\n",
    "count defines how many movies you want to display in the result.\n",
    "dim is the total number of movies, which is based on the length of vms. This suggests that vms is a matrix where each row represents a movie's features.\n",
    "dist is an empty square matrix of size (dim, dim), where each element will hold the distance between two movies.\n",
    "'''\n",
    "\n",
    "for i in range(dim):\n",
    "    for j in range(dim):\n",
    "        dist[i,j] = sq_dist(vms[i, :], vms[j, :])\n",
    "'''\n",
    "The nested loops iterate over every pair of movies (i, j), where i and j are movie indices.\n",
    "sq_dist(vms[i, :], vms[j, :]) calculates the squared distance between the features of the i-th and j-th movies. This function likely measures how similar or dissimilar the two movies are based on their feature vectors (vms[i, :] and vms[j, :]).\n",
    "The distance is stored in the matrix dist[i, j].\n",
    "'''        \n",
    "m_dist = ma.masked_array(dist, mask=np.identity(dist.shape[0]))  # mask the diagonal. This line creates a version of the dist matrix where the diagonal (self-comparisons) is hidden (masked) so that they are ignored in further operations like finding the most similar movies.\n",
    "'''\n",
    "m_dist is a masked version of the distance matrix dist. np.identity(dist.shape[0]) creates a matrix where the diagonal elements are 1 and all off-diagonal elements are 0.\n",
    "This identity matrix is used as a mask, which will mask out (ignore) the diagonal elements in the distance matrix (the self-comparisons, i.e., comparing a movie to itself).\n",
    "'''\n",
    "disp = [[\"movie1\", \"genres\", \"movie2\", \"genres\"]] #disp is a list that will hold the table rows. The first row is the header row that defines the columns: \"movie1\", \"genres\", \"movie2\", \"genres\".\n",
    "for i in range(count):\n",
    "    min_idx = np.argmin(m_dist[i])\n",
    "    movie1_id = int(item_vecs[i,0])\n",
    "    movie2_id = int(item_vecs[min_idx,0])\n",
    "    disp.append( [movie_dict[movie1_id]['title'], movie_dict[movie1_id]['genres'],\n",
    "                  movie_dict[movie2_id]['title'], movie_dict[movie1_id]['genres']]\n",
    "               )\n",
    "'''\n",
    "for i in range(count): Loop over the first count movies (in this case, 50).\n",
    "np.argmin(m_dist[i]): Find the index of the movie in the i-th row of m_dist that has the smallest distance (i.e., most similar) to movie i.\n",
    "movie1_id = int(item_vecs[i,0]): Get the movie ID for movie1 (the i-th movie).\n",
    "movie2_id = int(item_vecs[min_idx,0]): Get the movie ID for the most similar movie (min_idx).\n",
    "Then, the title and genres of movie1 and movie2 are fetched from movie_dict and added to the display list disp.\n",
    "'''\n",
    "table = tabulate.tabulate(disp, tablefmt='html', headers=\"firstrow\")\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where:\n",
    "\n",
    "movie1 is a movie from the dataset.\n",
    "\n",
    "movie2 is the most similar movie to movie1.\n",
    "\n",
    "The genres of both movies are displayed as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results show the model will generally suggest a movie with similar genre's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_dist = ma.masked_array(dist, mask=np.identity(dist.shape[0])) \n",
    "'''\n",
    "What it does:\n",
    "    ma.masked_array: This is a function from the numpy.ma (masked array) module, which creates a masked array. A masked array allows you to mark certain elements as \"masked\", meaning those elements are ignored in computations or operations. This is useful when you want to exclude certain values from processing, such as avoiding division by zero, excluding missing data, etc.\n",
    "    dist: This is a matrix of distances between movies. It is calculated using the squared distances between movie feature vectors, where each element represents the distance between two movies.\n",
    "    mask=np.identity(dist.shape[0]): The mask parameter creates a mask that determines which elements of the dist matrix should be masked. Let's break it down further:\n",
    "        np.identity(dist.shape[0]): This generates an identity matrix of size (n, n) where n is the number of movies (dist.shape[0]). An identity matrix has 1s on the diagonal and 0s off the diagonal.\n",
    "    For example, if you have a 3x3 distance matrix, the identity matrix will look like this:\n",
    "    [[1, 0, 0],\n",
    "    [0, 1, 0],\n",
    "    [0, 0, 1]]\n",
    "\n",
    "\n",
    "The identity matrix is used as the mask, meaning the diagonal elements (where the movie is compared to itself) will be marked as \"masked\", and these values will be excluded from computations.\n",
    "m_dist = ma.masked_array(dist, mask=np.identity(dist.shape[0])): This line creates a masked version of the dist matrix. The diagonal elements (where np.identity has 1s) are \"masked\", so they are effectively ignored. The off-diagonal elements (the distances between different movies) remain unmasked.\n",
    "Why is this done?\n",
    "Masking the diagonal: The diagonal elements represent the distance of a movie to itself, which will always be zero (since the distance between a movie and itself is zero). These self-distances are not useful when you are trying to find the most similar movies, so masking them prevents them from interfering with similarity calculations.\n",
    "How it affects further operations: When you perform operations on m_dist later (e.g., finding the most similar movies), the diagonal elements will be ignored because they are \"masked.\" This ensures that the system doesn't mistakenly suggest a movie as its own most similar movie.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wouldn't it be better to use `m_dist = ma.masked_array(dist, mask=np.zeros(dist.shape[0]))`, since the distance of each movie from itself is zero, not one?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a great question! The key difference between using np.identity(dist.shape[0]) and np.zeros(dist.shape[0]) as the mask lies in the behavior of the mask and the role of the identity matrix.\n",
    "\n",
    "Explanation:\n",
    "\n",
    "Using np.identity(dist.shape[0]):\n",
    "\n",
    "The identity matrix has 1s on the diagonal and 0s off the diagonal.\n",
    "\n",
    "When you use np.identity(dist.shape[0]) as the mask, you're essentially masking the diagonal elements (self-distances) by setting them as \"masked\" values.\n",
    "\n",
    "This ensures that you are excluding the self-comparisons, which is what you want to do when you are finding the most similar movies.\n",
    "\n",
    "Result: You mask the self-comparisons (diagonal), even though the self-distance is zero. This avoids considering the zero distances between a movie and itself when looking for the most similar movies.\n",
    "\n",
    "Using np.zeros(dist.shape[0]):\n",
    "\n",
    "np.zeros(dist.shape[0]) will create a row vector (or column vector, depending on the context) of zeros.\n",
    "\n",
    "The mask will have zeros across all rows, meaning it won't actually mask anything. So all the elements in the dist matrix, including the diagonal (self-distances), will remain unmasked, i.e., no exclusions.\n",
    "\n",
    "This would not have the desired effect because you still want to mask the diagonal (self-comparisons) and exclude them from calculations.\n",
    "\n",
    "Why np.identity is preferred:\n",
    "\n",
    "Using np.identity(dist.shape[0]) creates a mask specifically targeting the diagonal of the distance matrix. The identity matrix represents the self-comparisons and is what you want to mask. By masking the diagonal, you ensure that the algorithm doesn't use the self-distances in further calculations when finding the most similar items.\n",
    "\n",
    "To summarize:\n",
    "\n",
    "np.identity(dist.shape[0]): Masks the diagonal (self-distances), which is what you want.\n",
    "\n",
    "np.zeros(dist.shape[0]): Doesn't mask anything because it doesn't affect the diagonal, leaving it unmasked and still included in calculations, which isn't the desired behavior here.\n",
    "\n",
    "So, np.identity(dist.shape[0]) is the correct approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.identity(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"6\"></a>\n",
    "## 6 - Congratulations! <img align=\"left\" src=\"./images/film_award.png\" style=\" width:40px;\">\n",
    "You have completed a content-based recommender system.    \n",
    "\n",
    "This structure is the basis of many commercial recommender systems. The user content can be greatly expanded to incorporate more information about the user if it is available.  Items are not limited to movies. This can be used to recommend any item, books, cars or items that are similar to an item in your 'shopping cart'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary><font size=\"2\" color=\"darkgreen\"><b>Please click here if you want to experiment with any of the non-graded code.</b></font></summary>\n",
    "    <p><i><b>Important Note: Please only do this when you've already passed the assignment to avoid problems with the autograder.</b></i>\n",
    "    <ol>\n",
    "        <li> On the notebookâ€™s menu, click â€œViewâ€ > â€œCell Toolbarâ€ > â€œEdit Metadataâ€</li>\n",
    "        <li> Hit the â€œEdit Metadataâ€ button next to the code cell which you want to lock/unlock</li>\n",
    "        <li> Set the attribute value for â€œeditableâ€ to:\n",
    "            <ul>\n",
    "                <li> â€œtrueâ€ if you want to unlock it </li>\n",
    "                <li> â€œfalseâ€ if you want to lock it </li>\n",
    "            </ul>\n",
    "        </li>\n",
    "        <li> On the notebookâ€™s menu, click â€œViewâ€ > â€œCell Toolbarâ€ > â€œNoneâ€ </li>\n",
    "    </ol>\n",
    "    <p> Here's a short demo of how to do the steps above: \n",
    "        <br>\n",
    "        <img src=\"https://drive.google.com/uc?export=view&id=14Xy_Mb17CZVgzVAgq7NCjMVBvSae3xO1\" align=\"center\" alt=\"unlock_cells.gif\">\n",
    "</details>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOFYdA6zQJ1FpgYwYmRIeXa",
   "collapsed_sections": [],
   "name": "Recsys_NN.ipynb",
   "private_outputs": true,
   "provenance": [
    {
     "file_id": "1RO0HLb7kRE0Tj_0D4E5I-vQz2QLu3CUm",
     "timestamp": 1655169179306
    }
   ]
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "tf-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
